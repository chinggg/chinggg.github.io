<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>论文笔记 on chinggg的博客</title><link>https://chinggg.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link><description>Recent content in 论文笔记 on chinggg的博客</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 14 Mar 2022 13:46:52 +0000</lastBuildDate><atom:link href="https://chinggg.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml"/><item><title>FuzzBuilder: Automated building greybox fuzzing environment for C/C++ library</title><link>https://chinggg.github.io/post/fuzzbuilder/</link><pubDate>Mon, 14 Mar 2022 13:46:52 +0000</pubDate><guid>https://chinggg.github.io/post/fuzzbuilder/</guid><description>本文将对 ACSAC 2019 会议论文 FuzzBuilder: Automated building greybox fuzzing environment for C/C++ library 进行解读。这篇论文的主要亮点是利用单元测试为没有可执行文件的库自动生成 Fuzz 环境，通过修改 LLVM IR 以收集 seeds 并生</description></item><item><title>RAZOR: Software Debloating</title><link>https://chinggg.github.io/post/razor/</link><pubDate>Tue, 08 Feb 2022 13:46:52 +0000</pubDate><guid>https://chinggg.github.io/post/razor/</guid><description>RAZOR: software debloating 论文信息 原文作者：Chenxiong Qian, Hong Hu, Mansour Alharthi, Pak Ho Chung, Taesoo Kim, and Wenke Lee, Georgia Institute of Technology 原文标题：RAZOR: A Framework for Post-deployment Software Debloating 发表会议：USENIX SECURITY &amp;lsquo;19 原文</description></item><item><title>Local Differential Privacy for IoV</title><link>https://chinggg.github.io/post/ldp-iov/</link><pubDate>Thu, 13 Jan 2022 21:20:48 +0800</pubDate><guid>https://chinggg.github.io/post/ldp-iov/</guid><description>A survey of local differential privacy for securing internet of vehicles Intro IoV facilitates human’s life but benefits come with huge price of data privacy. In academia, differential privacy (DP) is proposed and regarded as an extremely strong privacy standard, which formalizes both the degree of privacy preservation and data utility. But DP suffers from a drawback in many practical scenarios because the paradigm</description></item><item><title>ML-Leaks: Membership Inference Attacks and Defenses on Machine Learning Models</title><link>https://chinggg.github.io/post/ml-leaks/</link><pubDate>Sat, 22 May 2021 13:46:52 +0000</pubDate><guid>https://chinggg.github.io/post/ml-leaks/</guid><description>前言 本文将对 NDSS (Network and Distributed System Security Symposium) 2019 获奖论文 ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models 进行解读。这篇论文的主要研究内容是针对机器学习模型的成员推理攻击（membe</description></item></channel></rss>