<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>安全 on chinggg的博客</title><link>https://chinggg.github.io/tags/%E5%AE%89%E5%85%A8/</link><description>Recent content in 安全 on chinggg的博客</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 05 Mar 2022 13:46:52 +0000</lastBuildDate><atom:link href="https://chinggg.github.io/tags/%E5%AE%89%E5%85%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>End-to-End Captcha Recognition With Few Labels: From SimGAN to Transfer Learning</title><link>https://chinggg.github.io/post/captcha-ml/</link><pubDate>Sat, 05 Mar 2022 13:46:52 +0000</pubDate><guid>https://chinggg.github.io/post/captcha-ml/</guid><description>基本信息 摘要：验证码是保护网站免受恶意攻击的一种常见机制，其中基于文本的验证码使用最为广泛。虽然机器学习技术已对其安全造成威胁，但现有的大多</description></item><item><title>RAZOR: Software Debloating</title><link>https://chinggg.github.io/post/razor/</link><pubDate>Tue, 08 Feb 2022 13:46:52 +0000</pubDate><guid>https://chinggg.github.io/post/razor/</guid><description>RAZOR: software debloating 论文信息 原文作者：Chenxiong Qian, Hong Hu, Mansour Alharthi, Pak Ho Chung, Taesoo Kim, and Wenke Lee, Georgia Institute of Technology 原文标题：RAZOR: A Framework for Post-deployment Software Debloating 发表会议：USENIX SECURITY &amp;lsquo;19 原文</description></item><item><title>Local Differential Privacy for IoV</title><link>https://chinggg.github.io/post/ldp-iov/</link><pubDate>Thu, 13 Jan 2022 21:20:48 +0800</pubDate><guid>https://chinggg.github.io/post/ldp-iov/</guid><description>A survey of local differential privacy for securing internet of vehicles Intro IoV facilitates human’s life but benefits come with huge price of data privacy. In academia, differential privacy (DP) is proposed and regarded as an extremely strong privacy standard, which formalizes both the degree of privacy preservation and data utility. But DP suffers from a drawback in many practical scenarios because the paradigm</description></item><item><title>ML-Leaks: Membership Inference Attacks and Defenses on Machine Learning Models</title><link>https://chinggg.github.io/post/ml-leaks/</link><pubDate>Sat, 22 May 2021 13:46:52 +0000</pubDate><guid>https://chinggg.github.io/post/ml-leaks/</guid><description>前言 本文将对 NDSS (Network and Distributed System Security Symposium) 2019 获奖论文 ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models 进行解读。这篇论文的主要研究内容是针对机器学习模型的成员推理攻击（membe</description></item></channel></rss>